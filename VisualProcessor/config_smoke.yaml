core_providers:
  # Minimal, fast smoke config to validate contracts end-to-end (Segmenter → VisualProcessor → NPZ/manifest).
  core_clip: true
  core_face_landmarks: true
  core_depth_midas: true
  core_object_detections: true
  core_optical_flow: true

modules:
  # Tier-0 modules smoke
  scene_classification: true
  face_detection: false
  detalize_face_modules: false
  emotion_face: false
  behavioral: false
  optical_flow: false
  action_recognition: false
  color_light: false
  frames_composition: false
  shot_quality: true
  cut_detection: true
  video_pacing: true
  story_structure: true
  micro_emotion: false
  similarity_metrics: true
  text_scoring: true
  uniqueness: true

global:
  root_path: null
  frames_dir: null
  rs_path: null
  max_parallel_modules: 1
  gpu_max_concurrent: "auto"

core_clip:
  model_name: "ViT-B/32"
  batch_size: "auto"
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

core_depth_midas:
  device: "auto"
  out_width: 256
  out_height: 256
  batch_size: "auto"
  frames_bgr: false
  save_full_res: false
  model_name: "MiDaS_small"
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

core_face_landmarks:
  venv_path: "/home/ilya/Рабочий стол/TrendFlowML/DataProcessor/VisualProcessor/core/model_process/core_face_landmarks/.core_face_landmarks_venv"
  use_pose: true
  use_hands: true
  use_face_mesh: true
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

core_object_detections:
  # YOLO path (no OWL queries) for smoke
  use_queries: false
  model: "yolov8n.pt"
  batch_size: "auto"
  device: "auto"
  box_threshold: 0.6
  iou-threshold: 0.3
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

core_optical_flow:
  device: "auto"
  model: "small"
  max_dim: 256
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

scene_classification:
  # Tier-0: deterministic (no CLIP semantics), but keep advanced heuristic features enabled
  enable_advanced_features: true
  use_clip_for_semantics: false
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

cut_detection:
  device: "auto"
  use_clip: false
  use_deep_features: false
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

shot_quality:
  device: "cuda"
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

video_pacing:
  downscale_factor: 0.25
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

story_structure:
  # Baseline uses only core_clip; args kept for compat but unused.
  clip_model: null
  sentence_model: null
  subtitles: null
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

uniqueness:
  repeat_threshold: 0.97
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

similarity_metrics:
  top_n: 10
  reference_embeddings_npz: null
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200

text_scoring:
  # OCR artifact is optional; module will produce a valid empty output if not found.
  ocr_npz: null
  use_face_data: false
  sampling:
    target_frames: 120
    min_frames: 60
    max_frames: 200


