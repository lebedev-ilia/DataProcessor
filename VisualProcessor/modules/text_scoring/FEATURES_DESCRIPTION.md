# Описание фичей модуля text_scoring

Модуль извлекает фичи текста по результатам OCR и анализирует их взаимодействие с видео.

## Baseline v1 (текущая реализация в пайплайне)

- **OCR внутри модуля не выполняется.** Модуль является consumer'ом OCR-артефакта (NPZ) от внешнего компонента.
- Если OCR-артефакт не найден — модуль **не падает**, а возвращает валидный empty результат:
  - `text_present=false`
  - `features.empty_reason="ocr_not_available"`
  - пустые `ocr_raw` / `ocr_unique_elements`

Поддерживаемый минимальный формат OCR NPZ:
- `ocr_raw` (object) → `list[dict]`, где каждый dict содержит минимум: `frame`, `bbox`, `text`/`text_raw`, `confidence`.

## 1. Text → Action / Motion Correlation

### text_action_sync_score
Робастная оценка синхронизации текста с движением/действием.  
Для каждого уникального текстового элемента берётся окно вокруг первого появления текста \([t-w, t+w]\) в секундах (по умолчанию \(w \approx 0.5\) секунды), в котором вычисляются максимум и среднее z-score движения (по всему видео).  
`text_action_sync_score` — trimmed-mean (усечённое среднее) этих оконных значений по всем текстовым элементам. Высокие значения означают, что текст стабильно появляется рядом с пиками движения.

### text_motion_alignment
Средняя оценка мультимодального выравнивания текста с моментами активности.  
Для каждого уникального текстового элемента берётся момент первого появления, и считается:
`alignment = w_motion * motion_norm + w_face * face_norm + w_audio * audio_norm`,  
где `*_norm` — нормализованные в [0,1] сигналы движения/лиц/аудио, а веса \(w\) задаются в конструкторе пайплайна и суммируются в 1.0.  
`text_motion_alignment` — среднее значение alignment по всем элементам.

### text_motion_alignment_windowed
Оконная версия alignment. Для каждого текстового элемента берётся окно \([t-w, t+w]\), внутри которого считается максимум мультимодального alignment (motion+face+audio).  
`text_motion_alignment_windowed` — среднее значение этого оконного максимума по всем элементам. Лучше отражает, насколько текст совпадает с пиками мультимодальной активности с учётом временного лага.

### multimodal_attention_boost_score
Максимальная оценка мультимодального выравнивания текста (по всем уникальным элементам).  
Показывает пиковый момент, когда текст максимально синхронизирован с визуальными и аудио сигналами.

### multimodal_attention_boost_position
Относительная позиция (0..1) текста, дающего максимум по `multimodal_attention_boost_score`.  
Вычисляется как `time_max / video_length_seconds`. Позволяет понимать, где именно в ролике находится главный "текстовый пик" внимания.

## 2. Text Duration and Continuity

### text_on_screen_continuity
Средняя длительность отображения уникального текста на экране в секундах.  
Уникальные текстовые элементы определяются через дедупликацию по IoU bbox (> 0.6) и нормализованной текстовой похожести (> 0.8). Для каждого элемента берётся длительность от первого до последнего появления.

### text_on_screen_continuity_normalized
Средняя длительность текста, нормализованная на длину видео:  
`text_on_screen_continuity_normalized = mean_duration_sec / video_length_seconds`.

### text_on_screen_continuity_median
Медианная длительность отображения уникального текста в секундах.

### text_on_screen_continuity_max
Максимальная длительность отображения уникального текста в секундах.

### text_on_screen_continuity_std
Стандартное отклонение длительности отображения текста (robustness к "мигающим" и "долго висящим" надписям).

### text_switch_rate
Частота смены текста на экране: количество уникальных текстовых элементов на секунду видео:  
`text_switch_rate = num_unique_texts / video_length_seconds`.  
Показывает, насколько динамично меняется текст в ролике (особенно релевантно для форматів с "быстрым" текстом).

### num_unique_texts
Количество уникальных текстовых элементов после дедупликации (по IoU и текстовой похожести).

### time_to_first_text_sec
Время (в секундах) до появления первого текста в видео.

### time_to_first_text_position
Нормализованная позиция первого текста: `time_to_first_text_sec / video_length_seconds`.

### text_area_fraction
Средняя доля площади кадра, занимаемая текстом. Для каждого уникального элемента берётся медианный bbox, его площадь делится на площадь кадра; затем усредняется по всем элементам. Требует указания `frame_width` и `frame_height` при инициализации пайплайна.

## 3. Call-to-Action (CTA) Detection

### cta_presence
Оценка вероятности наличия CTA в видео (0..1).  
CTA определяется как комбинация:
- флагов `is_cta_candidate` из OCR,  
- нечеткого совпадения с CTA-ключевыми словами (EN/RU) по нормализованному тексту (fuzzy match ≥ 0.75 или попадание ключа как подстроки).  
`cta_presence` учитывает как количество обнаруженных CTA-элементов, так и их усреднённую уверенность.

### cta_timestamp
Средний временной момент появления CTA в секундах (обратная совместимость).  
Фактически совпадает с `cta_mean_timestamp`.

### cta_first_timestamp / cta_mean_timestamp / cta_last_timestamp
Соответственно: время первого, среднего и последнего появления CTA в секундах среди всех CTA-элементов.

### cta_first_position / cta_mean_position / cta_last_position
Относительные позиции (0..1) первого, среднего и последнего CTA в видео:  
`position = timestamp / video_length_seconds`.

### cta_strength
Средняя сила CTA, вычисляемая как усреднённое мультимодальное выравнивание (motion+face+audio, нормализованные в [0,1]) для CTA-элементов. Значение ограничено диапазоном 0..1.  
Отражает, насколько CTA появляется на фоне сильных визуальных/аудио пиков.

### persistent_cta_flag
Флаг наличия "стойкого" CTA — хотя бы один CTA-элемент, который удерживается на экране дольше заданного порога (по умолчанию > 3 секунд). Полезно для анализа навязчивых или постоянно присутствующих призывов.

## 4. Text Emphasis Peaks

### text_emphasis_peak_flags
Список индексов текстовых элементов (не кадров), где мультимодальный текстовый скор (alignment) образует пики.  
Пики определяются через `scipy.signal.find_peaks` с ограничениями по prominence и минимальной дистанции, что даёт более устойчивое выделение "важных" текстовых моментов.

### text_emphasis_peak_prominence
Список значений prominence для каждого пика из `text_emphasis_peak_flags`. Отражает "выдающуюся" высоту пика относительно соседних значений.

### text_emphasis_peak_positions
Относительные позиции (0..1) текстовых пиков в видео, вычисленные по времени первого появления соответствующего текстового элемента.

## 5. Raw OCR Data

Модуль сохраняет как сырые OCR-детекции, так и агрегированные уникальные элементы.

### ocr_raw
Список детекций по кадрам (после фильтра по `confidence >= 0.4`):
- **frame**: индекс кадра  
- **time_s**: время в секундах (`frame / fps`)  
- **bbox**: координаты текста `[x1, y1, x2, y2]`  
- **text_raw** / **text**: исходный распознанный текст  
- **text_norm**: нормализованный текст (lowercase, trim, очистка краевой пунктуации)  
- **confidence**: уверенность OCR (0.0–1.0)  
- **language**: язык текста (если доступен)  
- **is_cta_candidate**: флаг, что этот фрагмент потенциальный CTA (по внешней логике или эвристикам).

### ocr_unique_elements
Список уникальных текстовых элементов с агрегированной информацией:
- **text_raw** / **text_norm**  
- **language**  
- **first_frame** / **last_frame**, **first_time** / **last_time**  
- **bbox_median**: медианный bbox по всем появлениям элемента  
- **aggregated_confidence**: средняя уверенность по всем кадрам элемента  

Именно по этим агрегированным элементам считаются длительности, CTA-метрики и text_on_screen_continuity.

### text_readability_score
Средний скор читаемости текста по всем уникальным элементам (0..1).  
Учитывает длину строки, среднюю длину слова и долю пунктуации: короткие, лаконичные заголовки и CTA получают более высокие значения.

### ocr_language_entropy
Энтропия распределения языков по уникальным текстовым элементам. Высокое значение означает смешение нескольких языков (мультиязычные ролики, кросс-таргетинг).

### text_movement_speed
Средняя скорость движения текстовых элементов по кадру (в долях диагонали кадра в секунду).  
Считается по смещению центров bbox во времени и отражает, насколько текст статичен или "бегущий".

## Методы вычисления

1. **OCR Extraction**: Внешний OCR (например, EasyOCR) формирует `ocr_data` с bbox, текстом, языком и уверенностью. Модуль фильтрует по `confidence`, нормализует текст и группирует детекции в уникальные элементы.
2. **Motion/Face/Audio Integration**: Модуль использует данные из других модулей (optical_flow, emotion_face, audio processor) для вычисления мультимодальных метрик и CTA-усиления.
3. **Normalization**: Все сигналы движения/лица/аудио нормализуются и сглаживаются через Gaussian filter; для energy-фич используется z-score по видео и робастные усреднения.

## Зависимости

- **easyocr**: Библиотека для OCR
- **numpy**: Для численных вычислений
- **scipy**: Для фильтрации сигналов

## Использование

Модуль может работать автономно или интегрироваться с данными из других модулей через флаги:
- `--use-motion-data`: Использовать данные движения из optical_flow
- `--use-face-data`: Использовать данные эмоций из emotion_face
- `--use-audio-data`: Использовать аудио данные

