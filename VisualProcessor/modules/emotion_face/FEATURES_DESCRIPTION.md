# Описание фичей модуля emotion_face

Модуль использует модель EmoNet для распознавания эмоций на лицах в видео. Обрабатывает только кадры с обнаруженными лицами (использует `core_face_landmarks.face_present`) и извлекает эмоциональные признаки, включая базовые эмоции Ekman, валентность/активацию, динамику эмоций и расширенные фичи.

## 1. Базовые эмоции (emotions)

### 8 классов эмоций Ekman

Вероятности для каждого кадра: Neutral, Happy, Sad, Surprise, Fear, Disgust, Anger, Contempt. Вычисляются через EmoNet: кадр с лицом предобрабатывается (RGB, нормализация), пропускается через модель, выход expression проходит через softmax для получения вероятностей по классам.

**Калибровка**: Применяется temperature scaling для калибровки вероятностей (параметр `temperature`, по умолчанию 1.0, может быть настроен на валидации).

### emotion_confidence

Уверенность в предсказании эмоции для кадра (0.0-1.0). Вычисляется как `max_softmax * face_confidence`, где `max_softmax` - максимальная вероятность среди всех эмоций, `face_confidence` - уверенность детекции лица (по `core_face_landmarks`, face_detection удалён). Используется для weighted aggregation и фильтрации низкокачественных кадров.

### is_valid

Флаг валидности кадра (bool). Кадры с низкой `face_confidence` (< 0.3) помечаются как `is_valid=false` и не используются в агрегатах без весов.

## 2. Valence и Arousal

### valence

Валентность (позитивность/негативность эмоции) в диапазоне от -1.0 (негативная) до 1.0 (позитивная). Извлекается напрямую из выхода EmoNet (out["valence"]), представляет непрерывное значение эмоциональной валентности.

### arousal

Активация (возбуждение/спокойствие) в диапазоне от -1.0 (спокойствие) до 1.0 (возбуждение). Извлекается напрямую из выхода EmoNet (out["arousal"]), представляет непрерывное значение эмоциональной активации.

## 3. Keyframes (ключевые кадры)

### global_index, local_index

Глобальный индекс кадра в видео и локальный индекс в обработанной последовательности. Используются для идентификации ключевых моментов.

### type

Тип ключевого кадра: "emotion_peak" (пик эмоции) или "transition" (эмоциональный переход). 

**Алгоритм детекции**:
- Перед детекцией применяется Gaussian smoothing (σ = 1-3 кадра) для сглаживания valence/arousal
- Пики детектируются через `scipy.signal.find_peaks` с параметрами `prominence ≥ 0.1` (в нормализованной шкале) и `min_distance = 8-12 кадров`
- Переходы детектируются через анализ изменений `|Δvalence|` и `|Δarousal|` с использованием тех же параметров prominence и distance
- Это снижает шум и обеспечивает более стабильную детекцию ключевых моментов

### emotion

Полные данные эмоции для ключевого кадра (valence, arousal, emotions). Содержат эмоциональное состояние в момент ключевого события.

## 4. Emotion Profile (профиль эмоций)

### dominant_emotion

Доминантная эмоция в видео, определяемая как наиболее часто встречающаяся доминантная эмоция по всем кадрам. Вычисляется через подсчет доминантных эмоций (эмоция с максимальной вероятностью) для каждого кадра и выбор наиболее частой.

### neutral_percentage

Процент кадров с доминантной эмоцией Neutral. Вычисляется как отношение количества кадров с максимальной вероятностью Neutral к общему количеству кадров.

### valence_avg, arousal_avg

Средние значения валентности и активации по всем кадрам. Вычисляются как **weighted mean** по `emotion_confidence`: `sum(value * confidence) / sum(confidence)`. Это обеспечивает, что кадры с низкой уверенностью вносят меньший вклад в агрегаты.

### valence_std, arousal_std

Стандартные отклонения валентности и активации. Показывают вариативность эмоциональных состояний.

## 5. Quality Metrics (метрики качества)

### diversity_score

Оценка разнообразия эмоций (0.0-1.0), вычисляемая как отношение количества уникальных доминантных эмоций к общему количеству классов (8). Высокие значения указывают на разнообразие эмоций в видео.

### transition_score

Оценка количества эмоциональных переходов, вычисляемая как отношение количества значимых переходов (изменение > threshold) к общему количеству кадров. Отражает динамику эмоциональных изменений.

### monotonicity_score

Оценка монотонности последовательности (0.0-1.0), вычисляемая как 1.0 минус нормализованное стандартное отклонение валентности и активации. Высокие значения указывают на монотонную последовательность без изменений.

### variance_score

Вариативность эмоций, вычисляемая как дисперсия максимальных вероятностей эмоций по всем кадрам. Отражает изменчивость интенсивности эмоций.

### different_emotions

Количество различных доминантных эмоций, обнаруженных в последовательности. Показывает разнообразие эмоциональных состояний.

### significant_transitions

Количество значимых эмоциональных переходов (изменение > threshold). Отражает количество резких изменений эмоций.

### max_monotonic_streak

Максимальная длина монотонной последовательности (без изменений эмоций). Показывает длительность стабильных эмоциональных состояний.

### overall_score

Комплексная оценка качества последовательности, комбинирующая diversity_score, transition_score, monotonicity_score и variance_score. Используется для валидации качества извлеченной последовательности.

### is_valid, is_monotonic

Флаги валидности (overall_score >= quality_threshold) и монотонности (monotonicity_score > threshold) последовательности. Используются для принятия решений о качестве данных.

## 6. Processing Stats (статистика обработки)

### total_frames, faces_found, segments, selected_frames

Общее количество кадров в видео, количество кадров с обнаруженными лицами, количество сегментов с лицами, количество выбранных для обработки кадров. Отражают процесс адаптивной выборки кадров.

### final_length, keyframes_count

Финальная длина последовательности после валидации и нормализации (обычно target_length=256), количество обнаруженных ключевых кадров. Показывают результат обработки.

### video_type

Тип видео: "STATIC_FACE" (статичное лицо), "CONTINUOUS_FACE" (непрерывное присутствие лица), "DYNAMIC_FACES" (динамические сцены). Определяется через анализ распределения кадров с лицами и сегментов.

## 7. Advanced Features (расширенные фичи)

### 7.1. Microexpressions (микроэмоции)

#### microexpressions_count

Количество обнаруженных микроэмоций (резких эмоциональных изменений длительностью 0.03-0.5 секунды). 

**Параметры детекции**:
- Минимальная длительность: **≥2 кадров** (на 30 fps 0.03s ≈ 1 кадр, что слишком мало для надежной детекции)
- Максимальная длительность: до 15 кадров (0.5 секунды при 30 fps)
- Порог изменения: **adaptive threshold** (85th percentile от frame-to-frame deltas), что обеспечивает адаптацию к различным типам видео
- Комбинированное изменение: `sqrt(Δvalence² + Δarousal²) + emotion_change_weight`

#### microexpression_rate

Частота микроэмоций (количество в секунду), вычисляемая как отношение количества микроэмоций к общей длительности видео. Отражает частоту резких эмоциональных реакций.

#### avg_duration

Средняя длительность микроэмоции в секундах. Вычисляется как среднее арифметическое длительностей всех обнаруженных микроэмоций.

#### microexpressions

Список детектированных микроэмоций с информацией о start_frame, end_frame, duration_sec, intensity, type (переход между эмоциями), valence_change, arousal_change. Позволяет анализировать конкретные моменты резких эмоциональных изменений.

### 7.2. Physiological Signals (физиологические сигналы)

⚠️ **ВАЖНО**: Эти метрики основаны на эвристических правилах и не являются валидированными клиническими индикаторами. Для продакшн-использования рекомендуется обучить learned meta-model (X → label) с размеченными данными или weak supervision. Текущая реализация использует правила как initial heuristics.

#### stress_level_score

Оценка уровня стресса (0.0-1.0), вычисляемая через комбинацию индикаторов: высокий arousal с отрицательной валентностью, высокая вероятность страха/гнева, высокая вариативность эмоций, частота микроэмоций. Высокие значения указывают на стрессовое состояние. **Heuristic-based, not validated for production use.**

#### confidence_face_score

Оценка уверенности (0.0-1.0), вычисляемая через комбинацию: положительная валентность, умеренный arousal, высокая вероятность счастья/нейтральности, низкая вариативность (стабильность). Высокие значения указывают на уверенное состояние. **Heuristic-based, not validated for production use.**

#### tension_face_index

Индекс напряжения (0.0-1.0), вычисляемый через комбинацию: высокий arousal, низкая вариативность (зажатость), высокая вероятность отрицательных эмоций (грусть, гнев, страх). Отражает физическое и эмоциональное напряжение. **Heuristic-based, not validated for production use.**

#### nervousness_score

Оценка нервозности (0.0-1.0), вычисляемая через комбинацию: высокая вариативность эмоций, высокий arousal, высокая вероятность страха/удивления, частота микроэмоций. Высокие значения указывают на нервозное состояние. **Heuristic-based, not validated for production use.**

### 7.3. Face Asymmetry (асимметрия лица)

#### asymmetry_score

Оценка асимметрии лица (0.0-1.0), вычисляемая через сравнение левой и правой половин лица на основе landmarks. Высокие значения указывают на асимметричное лицо.

#### eyebrow_asymmetry, mouth_asymmetry, eye_asymmetry

Асимметрия отдельных частей лица (брови, рот, глаза), вычисляемая через сравнение соответствующих landmarks левой и правой сторон. Отражает локальную асимметрию.

#### sincerity_score

⚠️ **AUDIT-ONLY / RESEARCH**: Оценка искренности (0.0-1.0), основанная на анализе естественности асимметрии. 

**ВАЖНО**: Эта метрика является **псевдопсихологической** и **НЕ должна использоваться в продакшн-моделях** без клинической валидации и юридической проверки. Используется только для исследовательских целей или аудита. Естественные эмоции обычно имеют некоторую асимметрию, в то время как фальшивые эмоции могут быть слишком симметричными или иметь неестественную асимметрию, но эта связь не является научно доказанной и может быть дискриминационной.

### 7.4. Emotional Individuality (индивидуальность выражения)

#### emotional_intensity_baseline

Базовая интенсивность эмоций, вычисляемая как среднее значение максимальных вероятностей эмоций по всем кадрам. Отражает общий уровень выразительности.

#### expressivity_index

Индекс выразительности, вычисляемый как стандартное отклонение максимальных вероятностей эмоций. Высокие значения указывают на высокую вариативность выразительности.

#### emotional_range

Эмоциональный диапазон, вычисляемый как разность между максимальной и минимальной максимальной вероятностью эмоций. Отражает разброс интенсивности эмоций.

#### dominant_style

Доминантный стиль выражения эмоций (например, "expressive", "reserved", "moderate"), определяемый на основе анализа паттернов интенсивности и вариативности.

#### emotional_style_vector

Вектор стиля выражения эмоций, характеризующий индивидуальные особенности выражения эмоций (интенсивность, вариативность, предпочтения к определенным эмоциям).

## 8. Per-frame features для VisualTransformer

Для подачи в Transformer (per-frame последовательность) используются следующие компактные фичи (~12-20 dims, можно ужать до ~10-12 через PCA):

- `valence` (scalar, -1..1)
- `arousal` (scalar, -1..1)
- `emotion_probs` (8 dims) или `dominant_emotion_onehot` (8 dims), можно использовать `emotion_embedding` (PCA 8→3) для экономии
- `emotion_intensity = sqrt(valence² + arousal²)` (1 dim)
- `emotion_confidence` (1 dim)
- `is_keyframe_flag` (binary) — peak/transition label
- `microexpression_flag` (binary) или `microexpression_intensity` (scalar)
- `face_tracking_id_norm` (optional, для multi-face видео)
- `timestamp_norm / frame_position` (1 dim)

## 9. Агрегаты (per-face / per-video — табличные фичи)

Для финального предиктора используются следующие агрегированные фичи:

- `dominant_emotion` (categorical / one-hot or top-1)
- `neutral_percentage`
- `valence_avg`, `arousal_avg` (weighted by confidence)
- `valence_std`, `arousal_std`
- `emotion_diversity` (unique_dom_emotions / 8)
- `transition_score` (fraction of frames with |Δintensity| > thr)
- `monotonicity_score` (1 - normalized_std of valence/arousal)
- `variance_score` (variance of max probs)
- `significant_transitions_count`
- `microexpressions_count`, `microexpression_rate`, `avg_microexpr_duration`
- `max_monotonic_streak`
- `overall_quality_flag / is_valid` (based on quality thresholds & confidence)
- `video_emotion_style` (cluster id from emotional_style_vector)
- `processing_stats` (faces_found, selected_frames, final_length)

**Advanced/meta scores** (только как outputs learned meta-model или audit-only):
- `stress_level_score`, `confidence_face_score`, `tension_face_index`, `nervousness_score`
- `sincerity_score` (⚠️ AUDIT-ONLY)

## Примечания

- Модуль обрабатывает только кадры с обнаруженными лицами (использует `core_face_landmarks.face_present`).
- Использует адаптивную обработку: сегментация видео, выборка кадров из сегментов, валидация качества, нормализация до target_length (256 кадров).
- Поддерживает retry стратегию с адаптацией параметров для различных типов видео (STATIC_FACE, CONTINUOUS_FACE, DYNAMIC_FACES).
- Оптимизирован для работы с большими видео через батчевую обработку и управление памятью.
- Расширенные фичи (микроэмоции, физиологические сигналы, асимметрия, индивидуальность) требуют временной последовательности эмоций для вычисления.
- **Калибровка**: Применяется temperature scaling для вероятностей EmoNet (настраивается на валидации).
- **Weighted aggregation**: Все средние значения вычисляются с весами по `emotion_confidence`.
- **Missing/confidence handling**: Кадры с низкой `face_confidence` помечаются `is_valid=false` и не используются в агрегатах без весов.

