Dynamic Batching — Q&A (Round 1: вопросы, затем ответы)

Цель: за несколько раундов зафиксировать **правила/контракты/интеграцию** Dynamic Batching именно для DataProcessor, затем реализовать и протестировать.

Связанный документ:
- `docs/models_docs/DYNAMIC_BATCHING_CHECKLIST.md` — чек-лист “стоимости на unit + constraints” для scheduler’а (seed заполняется по мере benchmark’ов).

#### Round 1 — вопросы (ответь списком)

1) **Scope в DataProcessor**: какие компоненты должны быть “batchable” в MVP (Visual core providers? Audio CLAP? Text embeddings?) и какие точно НЕ входят?

Ответ: “batchable” в MVP должны быть все компоненты которые физически имеет смысл батчить (такое правило исходит от того что у нас крайне ограничены ресурсы при очень требовательных алгоритмах и у нас буквально каждый мегабайт и каждая секунда на счету). Например возьмем алгоритм из AudioProcessor который считает темп аудио. Казалось бы это очень простой и легкий алгоритм который даже не требует GPU, но если у нас на вход этого алгоритма поступает например 3 аудио и по каждому 20 независимых сегментов (в сумме 60 сегментов), то если мы грамотно расспаралелим их анализ мы можем добиться скорости x10 или более (если один сегмент обрабатываеться 1 секунду то с правильным параллелизмом это будет 10 секунд на 60 сегментов что в масшабах огромной сисетмы супер результат).

2) **Единица батчинга**: для Visual — батчим кадры, клипы, “батчи кадров из разных видео”, или смесь? Для Audio — чанки? Для Text — строки/документы?

Ответ: Для каждого Processor должна быть задокументирована своя еденица обработки (батчинга), исходя из того какой результат мы хотим получить от этого процессора и какой у него вход - это очень важный вопрос, так как от него будет зависеть итоговый чек-лист по каждому процессору в котором будет описаны время и память на обработку одной еденицы и по этому чек-листу потом и будет строитьсчя батчинг и расспределение памяти и рассчет оптимального времени. Мне нужны твои советы что бы определить эту еденицу для каждого процессора, а для этого нужно пройтись по модулям каждого и посмотреть что они трубуют на вход (где то это кадры, гдето клипы, где то сегменты и тд.). Важно что от каждого отдельного компонента мы требуем качественного результата и возможно где то стоит пересмотреть логику анализа, например если какой то компонент на данный момет обрабатывает кадры, но ему лучше обрабатывать клипы (группы кадров) то нужно задокументировать этот момент и изменить логику обработки, провести perfomance тесты компонента и задокументировать итоговые еденицы бработки и батчинга + пмять и время в чек-листе.

3) **Cross-video batching**: разрешаем ли в MVP смешивать разные `video_id` в одном GPU batch? Если да — какие ограничения (одинаковый `analysis_*`, одинаковая модель/engine/precision, max videos per batch)?

Ответ: Давай свои советы. (я думаю что разрешаем но нужно хорошо подумать над логикой)

4) **Где живёт scheduler**: DataProcessor сам принимает решения (in-process scheduler), или он предоставляет “batching hints/контракты”, а реальные решения принимает внешний scheduler (Backend-level)? Какой интерфейс между ними?

Ответ: 
Fetcher: На вход scheduler поступают 40 url (неважно для обучения моделей или это уже запросы пользователей из продакшена, суть одна, меняеться только размер входа). Далее первым делом scheduler должен сформировать Batch level 1 для Fetcher исходя из времени и памяти, которое Fetcher тратит на 1 URL, и доступной памяти. Например scheduler решает сделать 4 потока по 10 URL - ок. Далее scheduler отправляет эту инфо в оркестратор (оркестратор 1 уровня) который уже запускает Fetcher в 4 потоках. оркестратор и Fetcher не имеют права менять параметры батчинга 1 уровня (Batch level 1). Касательно именно Fetcher я не знаю есть ли смысл делать батчинга 2 уровня, то есть разбивать это 10 url еще раз. По итогу Fetcher формирует готовую метадату и отдает путь к ней обратно оркестратору. оркестратор отдает какие то данные (длительность видео, время сбора и тд.) из метадаты в scheduler что бы он зафиксировал итоговое время и возможно скоректировал константы (в чек-листе), а также понимал как он будет распределять эти данные дальше в DataProcessor исходя из длительности и тд.
DataProcessor: scheduler формирует батч 1 уровня для DataProcessor. И также отдает в оркестратор 1 уровня, который запускает DataProcessor. Далее касательно имменно DataProcessor, поскольку это очень большая система, в ней будут батчинги нескольких уровней (уже в самом DataProcessor), например батчинг (расспаралеливание) 2 уровня между процесорами (данные по одному видео сразу можно расспаралелить в Segmenter и в TextProcessor так как они почти не связаны, кроме OCR - текст в кадрах, но TextProcessor может пока работать с метаинформацие и остановиться пока не получит статус отработки OCR в VisualProcessor. Также с AudioProcessor). Далее батчинг 3 уровня уже в самих процессорах, например расспаралеливание по модулям + также по видео. Далее батчинг 4 уровня - это расспаралеливание уже в самом модуле, например подавать батч в какуюто модель или просто расспаралеливать алгоритмы ынутри модуля.
Models: тут все тоже самое по аналогии с выше сказаным.
Итог: Тут нужно понять как регулировать все эти уровни батчинга и как выстраивать взаимосвязи с верхним scheduler (как минимум ему доджны приходить отчеты о фактичеком времени что бы он коректировал константы). Тут нужны твои советы и рекомендации + новые вопросы в новый рануд.

5) **Resource checklist**: откуда берётся “стоимость” (VRAM/latency) на unit для компонента: статический YAML/JSON, БД, автопрофилирование? Кто источник правды?

Ответ: Для формирования первоначального чек-листа мы должны провести тесты для каждого компонента каждого процессора и каждой возможной входящей еденицы, например есть модуль object_detection к нему на вход поступает еденица обработки (как видишь пока мы не решили что будет еденицей для конкретного модуля), сейчас для примера предположим что это один кадр. так вот Суть нашего теста для object_detection будет замерить время обработки и затраченую память на один кадр в разных разрешениях (например 640, 720, 1080) и задокументировать все это с версионированием, например: версия 1.0, разрешение 640, GPU устройство: RTX 2060, доступная память GPU: 6гб, еденица обработки: 1 кадр, время: 1 секунда, память: 100мб. И так для каждого разрешения. По анологии с AudioProcessor, TextProcessor и Segmenter. Далее этот первоначальный файл будет динамически корректировать уже самим scheduler (автопрофилирование). Это все мое виденье. Жду твои советы и рекомендации.

6) **GPU memory model**: считаем ли, что память “освобождается между кадрами”, или учитываем пики/кэш (weights pinned, activations, allocator fragmentation)?
Ответ: Реши сам

7) **OOM поведение**: при OOM что допускается:
   - уменьшить batch_size и retry (сколько попыток, какой backoff)?
   - уменьшить resolution/кол-во кадров (деградация данных)?
   - переключить device (cuda→cpu) — запрещено по no-fallback или допустимо только для отдельных компонентов?
   Ответ: при OOM: 3 попытки уменьшения batch_size - последняя попытка batch_size = 1. Никакой деградации данных. cuda→cpu запрещено по no-fallback

8) **Fairness/latency**: цель оптимизации — throughput, latency per run, или cost? Нужны ли приоритеты (paid users), SLA, starvation protection?
Ответ: Не совсем понимаю что это. (Если хватает данных - реши сам)

9) **Batch windows**: допускаем ли “подождать N ms/сек” ради наполнения batch (как backend buffer 5–10 сек), или только внутри одного run без ожидания?
Ответ: Одназначно. (Я вроде это уже описывал). По логичным соображения относиться только к продакшену. backend buffer - 10 сек (при этом у пользователя уже идет прогресс, то есть не нужно ему на сайте показывать что мы вот мол ждем 10 секунд что бы добрать batch)

10) **Детерминизм**: требуется ли воспроизводимость результатов при разных batch shapes/ordering? Если да — что фиксируем в meta (seed, ordering, padding policy)?
Ответ: Реши сам (я думаю требуется)

11) **Observability**: какие метрики/поля обязаны появиться:
   - per-component `effective_batch_size`, `retries`, `oom_count`, `gpu_mem_peak_mb`, `queue_wait_ms`?
   - где это хранится: manifest/NPZ meta/logs/DB metrics?
   Ответ: Реши сам

12) **Интеграция с idempotency/cache**: batching влияет на ключ? Должен ли `batch_size` входить в `model_signature`, или это только runtime‑параметр (и где граница)?
Ответ: Реши сам

13) **Совместимость с Triton dynamic batching**: DataProcessor всегда отправляет micro-batches (Triton агрегирует), или DataProcessor “не батчит”, если `runtime=triton`?

Ответ: в ответе на вопрос 4 я уже описал уровневую систему батчинга (расспаралеливания). Так вот нам нужно решить где будет Triton в этой системе (отдельный уровень или как?) и как будет формироваться запрос к нему в плане батчинга.

14) **Границы ответственности**: что именно DataProcessor обязан сделать “уже сейчас” для интеграции, даже если Triton/Backend scheduler ещё не готов (интерфейсы, meta/manifest, resource hints)?

Ответ: Нужно решить как и кем контролируеться уровневая система батчинга. Исходя из этого решения мы будет реализовывать функционал DataProcessor. (выше я описал свое виденье, жду твой разбор + новый раунд вопросов)



---

## Round 1 — итог (зафиксированные решения / decision log)

1) **MVP scope (batchable)**:
- В MVP **все компоненты, где это имеет смысл**, должны быть batchable (даже CPU‑алгоритмы), т.к. ресурсы ограничены и важен выигрыш по времени/параллелизму.

2) **Многоуровневый batching (иерархия)**:
- Есть **уровни batching**:
  - Level 1 (верхний scheduler): формирует batch для Fetcher и batch для DataProcessor (как “job batches”).
  - Level 2 (внутри DataProcessor): параллелизм между процессорами (Segmenter/Text/Audio/Visual) с учётом зависимостей (например OCR).
  - Level 3 (внутри процессора): параллелизм по модулям и/или по видео (если разрешён cross-video).
  - Level 4 (внутри модуля/модели): micro-batching при инференсе/внутренний параллелизм.
- **Оркестратор 1 уровня** и сами компоненты **не имеют права менять Batch level 1**, полученный от верхнего scheduler (они обязаны ему следовать).
- Оркестраторы/компоненты должны **репортить фактические метрики** обратно (время/возможные поправки к константам), чтобы scheduler мог автокорректировать чек‑лист.

3) **Resource checklist / baseline profiling**:
- Начальный чек‑лист строится через **перф‑тесты каждого компонента** по “единице обработки” и режимам (разрешение 640/720/1080, устройство, доступная VRAM и т.д.) с версионированием.
- Далее чек‑лист **динамически корректируется** scheduler’ом (автопрофилирование).

4) **OOM policy (MVP)**:
- При OOM: **3 попытки** уменьшения batch_size, последняя попытка — `batch_size=1`.
- **Никакой деградации данных** (не уменьшаем resolution/кол-во кадров как OOM‑fallback).
- **cuda→cpu запрещено** (no-fallback).

5) **Batch windows (prod)**:
- В проде допускаем backend buffering для наполнения batch: **10 секунд**, но пользователь при этом видит прогресс (“в очереди”), т.е. UI не “зависает”.

## Round 1 — открытые вопросы (нужен Round 2)

- **Единица обработки/batching** для каждого процессора/модуля (кадр vs клип vs сегмент vs чанк) — требуется аудит модулей + возможный рефактор логики.
- **Cross-video batching**: разрешаем ли в MVP и какие ограничения.
- **GPU memory model**: “освобождается между кадрами” vs учитывать пики/кэш/фрагментацию.
- **Цель оптимизации (throughput/latency/cost)** и нужна ли приоритизация.
- **Детерминизм** при разных batch shapes/ordering и что фиксируем в meta.
- **Observability**: какие метрики и куда пишем (manifest/NPZ meta/DB).
- **Idempotency/cache**: входит ли `batch_size` в `model_signature` или это только runtime‑параметр.
- **Triton**: где он в этой уровневой системе и как DataProcessor batching сочетается с Triton dynamic batching.

---

## Round 2 — вопросы (на уточнение контракта; ответь списком)

1) **Единица обработки (обязательно выбрать для MVP)**:
   - Segmenter: единица = ? (кадр / секунда / “batch кадров” / segment)
   - Visual core providers: единица = ? (кадр / клип / batch кадров)
   - Visual modules: единица = ? (кадр / клип / batch кадров)
   - AudioProcessor: единица = ? (аудио-сегмент / fixed-length chunk / whole track)
   - TextProcessor: единица = ? (документ / набор строк / комментарий)

Ответ: Ты сам должен ответить на этот вопрос. Пройдисть по каждому процессору и каждому их модулю, пойми суть модуля и то чем он полезен системе, далее пойми какой ему нужен вход для получения максимально качественноо выхода. Отсюда и сформируй еденицу обработки и батчинга. Последовательно фиксируй эти еденицы в документах.

2) **Cross-video batching (MVP)**:
   - Разрешаем ли смешивать разные `video_id` в одном batch на Level 3/4?
   - Если да: max videos per batch = ? и какие preconditions обязательны (одинаковый `analysis_*`, одинаковый `model_signature`, одинаковый device/precision)?

Ответ: Разрешаем ли смешивать разные `video_id` - да. max videos per batch реашется динамически исходя из оптимального времени и достпуной памяти. Остальное реши сам.

3) **Граница между Level 2 и Level 3**:
   - DataProcessor Level 2 (между процессорами): разрешаем ли одновременный запуск Visual+Audio+Text при условии, что Segmenter уже готов?
   - OCR dependency: TextProcessor может стартовать “до OCR”, а потом догружать OCR текст, или OCR делает отдельный “Text stage”?

Ответ: Должен быть внешний файл состояний (прогресс для каждого видео) на который опираеться каждый процессор и модуль (кстатити этот файл также можно использовать для Frontend). То есть мы можем запустить Visual+Audio+Text но каждый их модуль всегда читает файл состояния и если допустим TextProcessor дошел до обработки OCR но в файле состояния еще нет данных о том что VisualProcessor дошел до этого этапа, то и соответственно TextProcessor, именно по этому видео, не идет дальше, а ждет OCR от VisualProcessor переодически читая файл состояния, но при этом TextProcessor может обрабатывать другие видео.

4) **GPU memory model (MVP правило)** — выбери один вариант:
   - A) планируем по “per-task VRAM” и считаем память квазилинейной, с safety margin (%), без учёта фрагментации;
   - B) учитываем “pinned weights + activation peak” и держим headroom (например 20–30%);
   - C) другое (опиши).

Ответ: реши сам

Decision (зафиксировано):
- Выбираем **вариант B**: учитываем **pinned weights + activation peak** и держим headroom.
- MVP правило вычисления batch_size для GPU‑тасков:
  - `free_vram_mb = gpu_total_mb - gpu_used_mb`
  - `headroom_mb = max(1024, round(free_vram_mb * 0.25))`
  - `effective_budget_mb = max(0, free_vram_mb - headroom_mb)`
  - `batch_size = clamp( floor(effective_budget_mb / gpu_memory_per_task_mb), 1, max_batch_size_component )`
- `gpu_memory_per_task_mb` берём из чек‑листа (`component_resource_requirements`) как “пик на unit” при текущих `analysis_*`/resolution bucket и `model_signature`.
- После каждого run/батча репортим фактический `gpu_mem_peak_mb` → scheduler может автокорректировать `gpu_memory_per_task_mb`.

5) **Retry/backoff для OOM**:
   - Ровно 3 попытки — ок. Какой backoff/пауза между попытками? (0s / 1s / exponential?)
   - Нужно ли логировать каждый OOM как warning или как error? (run должен падать только если batch_size=1 всё равно OOM?)

Ответ: 1. 2 секунды. 2. При разработке логируем каждый OOM как warning, но в проде просто как info. run должен падать только если batch_size=1 всё равно OOM.

6) **Цель оптимизации (MVP)**:
   - Что приоритетнее: throughput системы или latency per run?
   - FIFO достаточно или нужны приоритеты (paid/free)?

Ответ: реши сам

Decision (зафиксировано):
- MVP цель: **максимизировать throughput**, при этом не допускать starvation (FIFO как базовая fairness).
- MVP: **FIFO достаточно**, приоритеты (paid/free) отложены; интерфейс `priority` сохраняем как поле “на будущее”, но все = 0.

7) **Determinism (MVP)**:
   - Требуем ли одинаковые результаты при разном batching? (да/нет)
   - Если “да”: фиксируем ли ordering элементов в batch? Разрешаем ли nondeterministic kernels на GPU?

Ответ: реши сам

Decision (зафиксировано):
- Требуем **best-effort воспроизводимость**:
  - фиксируем `seed` (если применимо) и детерминированный **ordering элементов** в batch;
  - GPU nondeterministic kernels **допускаем** (иначе часто падает perf), но для компонентов с рандомом обязателен seed;
  - для тестов/дебага допускаем режим `--deterministic`, который включает строгую детерминизацию (медленнее).
- Ordering элементов в batch: сортировка по `(platform_id, video_id, unit_id)` внутри batch (стабильно).

8) **Observability (минимум MVP)**:
   - Какие поля обязательно пишем per-component:
     - `effective_batch_size`
     - `retries_total` (и `oom_retries`)
     - `queue_wait_ms` (если был backend buffer)
     - `gpu_mem_peak_mb` (если можем измерить)
   - Куда это писать в MVP: `manifest.json` vs NPZ `meta` vs DB metrics?

Ответ: реши сам

Decision (зафиксировано):
- Минимум MVP пишем:
  - В `manifest.json.components[]`: объект `batching`:
    - `effective_batch_size`, `retries_total`, `oom_retries`, `queue_wait_ms`, `gpu_mem_peak_mb` (если измеримо)
  - В NPZ `meta`: `batch_size`, `engine`, `precision`, `device_used` (и `models_used[]/model_signature` по `MODEL_SYSTEM_RULES.md`)
- В DB metrics — опционально (после появления БД/очереди), но структура должна быть совместима (export позже).

9) **Idempotency/cache**:
   - Должен ли `batch_size` входить в `model_signature`? (я предлагаю “нет”, но фиксировать в meta как runtime-параметр)
   - Входит ли `device`/`precision`? (по `MODEL_SYSTEM_RULES.md` — да)

Ответ: реши сам

Decision (зафиксировано):
- `batch_size` **НЕ входит** в `model_signature` (это runtime‑параметр), но **обязан быть в meta** для воспроизводимости.
- `device/precision/engine` входят в `model_signature` (как в `MODEL_SYSTEM_RULES.md`).

10) **Triton в системе уровней**:
   - Triton = Level 4 (micro-batching внутри модели), а DataProcessor даёт micro-batches (да/нет)?
   - Если Triton runtime: DataProcessor всё равно делает batching (например, по pre/post-processing), или полностью делегирует batching Triton’у?

Ответ: Реши сам

Decision (зафиксировано):
- Triton = **Level 4** (micro-batching внутри модели).
- DataProcessor делает batching на своём уровне:
  - группирует unit’ы в **micro-batches** для RPC к Triton (чтобы не слать по 1 запросу),
  - Triton затем может дополнительно агрегировать через свой dynamic batching.
- Если `runtime=triton`, DataProcessor **не отключает batching**: он остаётся важным для pre/post‑processing и для формирования эффективных запросов к Triton.

---

## Round 2 — итог (зафиксированные решения / decision log)

1) **Единица обработки**: требуется отдельный аудит модулей/процессоров; решение делаем “снизу вверх” (по пользе модуля и требуемому входу), фиксируем в документах.
2) **Cross-video batching**: **разрешён**; max videos per batch — **динамический** по ресурсам/времени. (Ниже зафиксированы constraints.)
3) **Параллельность Visual+Audio+Text**: разрешена, координация через **внешний state-file прогресса**; модули обязаны проверять state и ждать dependencies (например OCR), не блокируя обработку других видео.
4) **OOM retry/backoff**: 3 попытки; backoff = **2 секунды**; run падает только если `batch_size=1` всё равно OOM; logging: dev=warning, prod=info.
5) **Остальные 'реши сам'**: зафиксированы выше в Decision блоках (GPU memory model / оптимизация / детерминизм / observability / idempotency / Triton).

## Round 2 — constraints для cross-video batching (зафиксировано)

Cross-video batching разрешён **только если** выполняются все условия:
- одинаковый `component_name`
- одинаковый `model_signature` (а значит `models_used[]`, `engine`, `precision`, `device_policy`)
- одинаковые preprocessing параметры, влияющие на модель (min: `analysis_fps/analysis_width/analysis_height`, нормализация/resize policy)
- одинаковый “resolution bucket” (чтобы не раздувать паддинг/CPU resize внутри batch)
- единый `runtime` (`triton` или `inprocess`) и совместимый endpoint/device

Примечание: max videos per batch выбирается динамически, но мы всё равно введём **hard cap** (по умолчанию 8) как safety‑guard против гигантских batch’ей и starvation (можно поменять по результатам тестов).

---

## Round 3 — вопросы (да/нет + конкретные значения)

1) **State-file**: подтверждаешь, что он должен быть отдельным от `manifest.json` файлом (`run_state.json`) рядом с `manifest.json`, или можно считать `manifest.json` самим state-file (и расширить его)?

Ответ: отдельный файл

2) **State-file — минимальная схема**: какие обязательные поля ты хочешь видеть (минимум):
   - `run_id/platform_id/video_id/config_hash/sampling_policy_version`
   - `updated_at`
   - `stages`: `segmenter/audio/text/visual/render` со status
   - `checkpoints`: например `ocr_ready=true`, `frames_ready=true`
   - per-component status map?

Ответ: реши сам


3) **State-file concurrency**: будет ли несколько процессов/воркеров одновременно писать state/manifest одного run?

Ответ: Думаю что да. Есть предложение сделать уровневую систему state файлов то есть есть глобальный state-file level 1 над Fetcher, DataProcessor и Models, далее в каждом есть свои state-files и так вплодь до модулей и компонентов (level 2, 3, 4), у каждого есть mini-manager через который контролируеться доступ к state-file своего уровня, дабы избежать (или как то контролировать) concurrency. По заполнению нижних уровней обновляються верхние. Дай свои комментарии к этой идеи. Может она плохая и так лучше не делать или скоректировать ее.

4) **Polling interval** для ожидания зависимостей (например OCR): какое значение для MVP? (я предлагаю 0.5s) и нужен ли общий timeout?

Ответ: каждый модуль, если от него зависит другой модуль, так или иначе должен записать финальное состояние, например значение или error в state-file. Например мы запускаем одновременно TextProcessor и VisualProcessor. Предположим что TextProcessor быстрее дойдет до OCR чем VisualProcessor и ему придеться сколько то ждать. Так вот что бы рассчитать сколько ждать TextProcessor, сам TextProcessor должен иметь доступ к состояниям модулей в VisualProcessor (реализовываеться это через уровневую систему state-files). То есть TextProcessor закончил 3 модуля и 4 модулем идет анализ OCR, а VisualProcessor закончил 5 модулей, но получение OCR идет только 10 модулем. Так вот TextProcessor должен иметь доступ к чек-листу в котором описанно сколько примерно будут длиться оставшиеся 5 модулей у VisualProcessor и TextProcessor сможет рассичтать сколько примерно ему ждать до получения состояния OCR из VisualProcessor. Если через это время он не получил состояния он еще ждет определнное время, например 10 секунд. Если он не получает состояние выходит предупреждение или ошибка, которая как минимум должна попасть в scheduler что бы тот понял что в VisualProcessor что то не так. 

5) **Hard cap cross-video**: ок ли hard cap = 8 videos per micro-batch (плюс dynamic cap по VRAM)? Если нет — какое число/правило?

Ответ: ок

6) **Разделение batch windows**: backend buffer window = 10s — ок. Нужен ли “DataProcessor internal buffer window” (например 0.5–1s), чтобы собирать cross-video batch на GPU, или DP должен батчить только из уже готового batch level 1?

Ответ: только из уже готового batch level 1

7) **Priorities**: в доках есть `priority` (future). Подтверждаешь, что MVP = FIFO (all priority=0) и никаких paid/free сейчас?

Ответ: Приоритет задаеться заранее и зависит от взаимосвязи модулей и процессоров.

8) **OCR dependency**: уточни, что именно считается “OCR готово”:
   - готов core OCR NPZ артефакт в `result_store/.../ocr/...`
   - или готов отдельный “text_ocr.json” (но JSON артефакты запрещены)
   - или другое (укажи точный artifact name/path)

Ответ: VisualProcessor отвечает только за сбор OCR. TextProcessor за анализ OCR. То есть VisualProcessor не должен выполнять лишнюю работу - он должен собрать OCR например по группам кадров, сформировать data в которой указаны промежутки и сырой текст (либо токенизированый, но тогда должна быть зависимоть токенизатора между TextProcessor и VisualProcessor) и отдать в TextProcessor. TextProcessor должен получить (расшифровать ели текст токенизирован) и обработать. Если произошла какаято ошибка или текста нет на кадрах, VisualProcessor должен сообщить об этом в state-file, что бы TextProcessor не выдал ошибки и работал далее. Мы очень сконцентрировались на OCR, но это лишь одна из зависимостей, например между VisualProcessor и AudioProcessor также есть зависимости и то что я описал выше также к ним относиться.

9) **Checkpoint granularity**: state-file должен хранить прогресс только “по компонентам”, или ещё и “по unit’ам” (например сколько кадров из 100 обработано)?

Ответ: только по компонентам - обработал или нет (ожидание...), если да то как завершилась обработка (success, error).

10) **Интеграция с frontend**: фронт читает state из backend БД/API или прямо из MinIO/FS? (MVP рекомендация: через backend API; прямой доступ к storage обычно запрещаем).

Ответ: как ты скажешь так и сделаем


---

## Round 3 — итог (зафиксированные решения / decision log)

1) **State-file отдельно от manifest**:
- `run_state.json` — **отдельный файл** рядом с `manifest.json` (не расширяем `manifest.json` до state-machine).

2) **Concurrency и “уровневая система state-files” (идея)**:
- Ожидается конкурентная запись state/manifest несколькими процессами/воркерами.
- Предложена архитектура: **Level 1 global state** (Fetcher/DataProcessor/Models) + вложенные state-files Level 2/3/4 (процессоры → модули → компоненты).
- Для каждого уровня есть **mini-manager**, который контролирует доступ и обновления; нижние уровни обновляют верхние.

Комментарий/рекомендация (чтобы упростить реализацию MVP):
- Уровневую систему можно реализовать **без “зоопарка файлов”**:
  - либо *один* `run_state.json` с вложенными секциями `processors.visual.modules.*` и атомарными мерджами;
  - либо “write-only leaf files + aggregator”: каждый процессор пишет **только свой файл** (например `state_visual.json`), а верхний оркестратор агрегирует в `run_state.json`.
- В Round 4 нужно выбрать конкретную модель, иначе мы не сможем корректно решить lock/конкурентность.

3) **Ожидание зависимостей (wait)**:
- Модуль/процессор обязан записать финальное состояние (value/error) в state.
- Waiting модуль оценивает ожидание, зная:
  - текущий прогресс зависимого процессора (state),
  - чек‑лист длительностей оставшихся модулей (resource checklist).
- Если оценочное время вышло, ждём дополнительный “grace” (пример: **10 секунд**), затем пишем warning/error и отправляем сигнал scheduler’у.

4) **Cross-video batching hard cap**:
- Hard cap = **8 видео** на micro-batch (плюс dynamic cap по VRAM).

5) **Batch windows**:
- DataProcessor **не имеет своего internal buffer window**: батчит только из уже готового Batch level 1 (от верхнего scheduler).

6) **Priority (изменение относительно прошлых решений)**:
- Приоритет “задаётся заранее” и зависит от взаимосвязи модулей/процессоров.
- Это отличается от прежнего решения “MVP FIFO”; в Round 4 нужно уточнить: это **dependency-ordering** (топологический порядок) или **execution priority** (вытесняет FIFO).

7) **OCR dependency (разделение ответственности)**:
- VisualProcessor: **сбор OCR** (не анализ). Формирует данные по группам кадров с интервалами и raw/tokens text.
- TextProcessor: **анализ OCR** (и, если нужно, “расшифровка” токенов).
- Если OCR отсутствует/ошибка — VisualProcessor пишет это в state, чтобы TextProcessor **не падал** и продолжал дальше.
- Аналогичная логика зависимостей применима и для других связей (Visual↔Audio и т.п.).

8) **Checkpoint granularity**:
- State хранит прогресс **только по компонентам** (waiting/running/success/error), без per-unit прогресса.

9) **Frontend integration**:
- Решение делегировано: выберем путь (MVP рекомендуем backend API, не прямой доступ к storage).

---

## Round 4 — вопросы (нужно, чтобы финализировать контракт и начать реализацию)

1) **Модель state-files (выбери один вариант)**:
   - A) *Один файл* `run_state.json` (single source-of-truth), все писатели делают merge+lock.
   - B) *Leaf files per writer* (`state_visual.json`, `state_text.json`, …) + оркестратор агрегирует в `run_state.json`.
   - C) *Многоуровневые файлы* (как ты предложил) — Level1/Level2/Level3/Level4.

Ответ: 3 вариант

2) **Кто имеет право писать `run_state.json` (если A или B)?**
   - Только root orchestrator?
   - Или каждый процессор (Visual/Text/Audio/Segmenter) тоже пишет напрямую?

mini-manager (далее буду называть state-manager-level-...)

Ответ: Каждый компонент обращаеться к state-manager-level-3 (например на уровне VisualProcessor) и говорит что хочет обновить состояние, state-manager добавляет состояние в очередь и говорит компоненнту что его запрос сохранен и будет добавлен (в этот момент компонент не ждет, а получает статус и идет работать дальше), далее state-manager идет по очереди и обновляет state-file своего уровня, главное следить что бы состояния не терялись. Одновременно какой нибудь TextProcessor уже дождал до времени когда ему нужно получит состояние и сообщает своему state-manager-level-3 (на уровне TextProcessor) что бы тот обратился к state-manager-level-2 (на уровне DataProcessor) и запросил доступ к state-file-level-3 (на уровне VisualProcessor) и сообщил TextProcessor на каком там этапе VisualProcessor. Отвечая на вопрос: изменять state-file имеет право только state-manager того же уровня. Верхние уровни не могут изменять state-file нижнего уровня, а могут лишь обратиться к соответствующему state-manager для чтения текущего состояния его state-file. Но state-manager нижнего уровня соответственно может отправить запрос на state-manager верхнего уровеня что бы обновить тот обновил состояние.

3) **Locking/consistency (если конкурентная запись)**:
   - Подтверждаешь `flock` на уровне файла (и таймаут lock’а)?
   - Или достаточно атомарного replace + optimistic merge (read-modify-write) без lock?

Ответ: за lock отвечает state-manager своего уровня и своего state-file все запросы записи и чтения через state-manager 

4) **State schema (минимум MVP, утвердить поля)** — ок ли такая схема?
   - `run` (id/keys + `updated_at`)
   - `processors.{segmenter|visual|audio|text}`: `{status, started_at, finished_at, error_code?, error?}`
   - `components.<component_name>`: `{status, owner, depends_on[], wait_for[], started_at, finished_at, error_code?, artifact_paths?}`
   - `checkpoints`: `{ocr_ready, frames_ready, audio_ready, ...}`

Ответ: ок

5) **Статусы (утвердить enum)**:
   - `pending | running | waiting | success | empty | error | skipped`
   - Нужен ли отдельный `degraded`?

Ответ: Поля:
waiting - модуль еще не дошел до компонента
running - модуль дошел и выполняет компонент
success - модуль выполнил компонент и получил не нулевой результат (есть смысл читать результат)
empty - модуль выполнил компонент и получил нулевой результат (смысла читать результат нет)
skipped - ошибка выполнения предыдущего модуля из за которой вся работа модуля преостановлена
error - ошибка выполнения этого модуля

6) **Priority semantics (главный вопрос)**:
   - Что ты называешь “priority”: это **топологический порядок** (нельзя раньше зависимостей), или это **приоритет планирования** (какие задачи в очереди/батче исполнять раньше)?
   - Если это scheduling priority: какие уровни? (run-level / processor-level / component-level)

Ответ: “priority” это то что есть модули которые не могу начать свою работу без выхода другого модуля. о таких модулях мы должны заранее знать + нужно выстроить глобальную цепочку выполнения, что бы понимать какие модули можно выполнять параллельно. Глобальная цепочка подразумевает все алгоритмы, начиная с поступления url и заканчивая предсказанием + фичи для аналитики. Это удобно нарисовать виде дерева, причем свое дерево для каждого этапа (baseline/v1/v2), но что бы это дерево сделать мы должны утвердить модули и их фичи. 

7) **Dependency contract (как описываем зависимости)**:
   - Где мы описываем dependency граф: в DB profile, в `config.yaml`, в коде, или в state?
   - Нужен ли список “wait_on checkpoints” (например `wait_on: ocr_ready`)?

Ответ: реши сам

8) **OCR payload format (между Visual → Text)**:
   - Подтверди: OCR результат должен быть **NPZ артефактом** (а не JSON).
   - Минимальные поля в NPZ: `timestamps_sec`/`frame_indices`, `text_raw` (object array) или `tokens` + `tokenizer_id`, `spans` (start/end time), `empty_reason` если нет текста.
   - Где должен жить артефакт: `result_store/.../<component_name>/ocr_*.npz`? Название компонента?

Ответ: **NPZ артефактом**. Остальное реши сам

9) **Timeout/warn policy**:
   - Подтверди: после расчётного времени ожидания + grace (10s) → пишем `warning` в state и сигналим scheduler’у, но run продолжаем?
   - Когда ожидание становится **ошибкой** и останавливает run?

Ответ: Вообще нет. Если какой то модуль что то не отдал (после grace 10s) - на данный момент считаем это error и тормозим run.

10) **Frontend доступ к прогрессу**:
   - Утверждаем MVP: frontend читает прогресс только через **backend API**, backend читает `run_state.json`/`manifest.json` из storage.
   - Ок?

Ответ: ок

---

## Round 4 — итог (зафиксированные решения / decision log)

1) **Модель state-files**:
- Выбран вариант **C (многоуровневые файлы)**: Level 1/2/3/4.

2) **State-managers = единственные писатели**:
- Любая запись/чтение state-file идёт **только через state-manager соответствующего уровня**.
- Компоненты/модули **не пишут state напрямую**: они отправляют запрос state-manager’у, менеджер кладёт его в очередь и применяет к state-file (асинхронно).
- Верхние уровни **не изменяют** state-files нижних уровней напрямую; могут только читать через нижний state-manager.
- Нижний state-manager может инициировать обновление верхнего уровня через запрос верхнему state-manager.

3) **Locking/consistency**:
- За консистентность отвечает state-manager.
- Практическое правило для реализации: state-manager держит **single-writer** для своего файла; при записи state-file всё равно используем **atomic replace** (и при необходимости `flock`) внутри менеджера.

4) **State schema (MVP)**:
- Схема, предложенная в Round 4 (run/processors/components/checkpoints) — **ОК**.

5) **Enum статусов компонентов (MVP)**:
- `waiting`: модуль ещё не дошёл до компонента
- `running`: компонент исполняется
- `success`: завершился с ненулевым результатом (результат имеет смысл читать)
- `empty`: завершился с “нулевым” результатом (результат читать не нужно)
- `skipped`: ошибка предыдущего модуля остановила дальнейшую работу модуля
- `error`: ошибка выполнения этого модуля/компонента

6) **Priority = dependency-ordering (а не paid/free)**:
- “priority” = заранее известные зависимости между модулями (глобальный граф), чтобы строить цепочку и определять, что можно параллелить.
- Следствие: это **топологический порядок** по DAG (а не “вытеснение FIFO” по пользователям).

7) **Timeout/wait policy (строго)**:
- Если зависимость не пришла после оценочного ожидания + grace (пример: **10s**) → считаем это **error** и **останавливаем run** (fail-fast).

8) **OCR payload**:
- OCR handoff между Visual→Text делаем **NPZ артефактом** (не JSON).

9) **Frontend**:
- MVP: frontend читает прогресс только через **backend API** (backend читает state/manifest из storage).

---

## Dependency contract (закрываю “реши сам”)

Цель: зависимости должны быть **описаны декларативно** (DAG), чтобы:
- state managers могли выставлять `depends_on[]/wait_for[]`,
- scheduler/оркестратор могли строить корректный план параллелизма,
- было понятно, какие “priority” существуют.

Решение (MVP):
- **Source-of-truth DAG**: `DataProcessor/docs` → отдельный файл графа (пока без БД), затем мигрируем в БД (как часть `analysis_profiles/profile_components`).
- State-file — **не** источник правды графа; он только отражает runtime состояние.

Формат (MVP, предложено):
- Добавляем `docs/COMPONENT_GRAPH.md` или `docs/component_graph.yaml` (лучше YAML) со списком узлов:
  - `component_name`
  - `owner_processor` (`segmenter|visual|audio|text|models|fetcher`)
  - `depends_on_components[]` (жёсткие зависимости: без них компонент не стартует)
  - `soft_dependencies[]` (optional: влияет на качество, но не блокирует)
  - `wait_on_checkpoints[]` (сахар: например `ocr_ready`)
- Во время run оркестратор компилирует это в:
  - `run_state.checkpoints`
  - `run_state.components.<name>.depends_on[] / wait_for[]`

---

## OCR NPZ schema (закрываю “реши сам”)

Цель: VisualProcessor отдаёт **сырой OCR результат**, TextProcessor его анализирует.
Принцип: VisualProcessor **не токенизирует** по умолчанию (чтобы не тащить tokenizer dependency через процессоры). Токенизация — зона ответственности TextProcessor.

Предлагаемый компонент VisualProcessor:
- `component_name`: `ocr_extractor`
- artifact path (per-run): `result_store/<platform_id>/<video_id>/<run_id>/ocr_extractor/ocr.npz`

NPZ keys (минимум):
- `spans_sec`: `float32[N,2]` (start_sec, end_sec) — интервалы, к которым относится текст
- `text_raw`: `object[N]` — строки OCR (UTF-8)
- `span_frame_indices`: `object[N]` — список индексов кадров (в терминах `frames_dir` union) использованных для этого span (для воспроизводимости/дебага)
- `confidence`: `float32[N]` (опционально; если движок даёт confidence)

NPZ `meta` (как и везде):
- все required поля из `ARTIFACTS_AND_SCHEMAS.md` (`producer/schema/.../config_hash/.../status/empty_reason/...`)
- если OCR использует модель: `models_used[]` + `model_signature`

Семантика:
- если текст не найден → `status="empty"`, `empty_reason="no_text_detected"` (и массивы могут быть пустыми корректной формы)
- если OCR сломался → `status="error"` + `error_code="ocr_failed"` (и это должно попасть в state)

---

## Round 5 — вопросы (финализация перед реализацией)

1) **Названия state-files по уровням (утвердить)**:
   - Level 1: `state_level1_global.json` ?
   - Level 2 (DataProcessor/run): `run_state.json` ?
   - Level 3 (per processor): `state_visual.json`, `state_text.json`, `state_audio.json`, `state_segmenter.json` ?
   - Level 4 (per module/component): отдельные файлы или только записи внутри Level 3?

Ответ: с именами согласен. 4 уровень лишний. компоненты пишут состояние а файл процессора.

2) **Durability очереди state-manager**:
   - Очередь запросов state-manager должна быть in-memory (проще) или должна переживать падение процесса?
   - Если должна переживать: ок ли MVP вариант `state_events.jsonl` (append-only journal) рядом со state-file?

Ответ: реши сам. но я думаю что она должна быть во внешной памяти (внешний файл) что бы при каком то сбое (ошибке) мы могли вернуться к последнему стабильному состоянию и сделать retray.

3) **Где живут state-files (storage)**:
   - локальный диск worker’а (как сейчас `_runs/...`) или сразу MinIO/S3 adapter?
   - нужно ли читать state/manifest через тот же storage adapter, что и NPZ?

Ответ: state-files живут во внешнем хранилище. Это делаеться для того что бы в любой момент можно было приостановить анализ и потом снова начать его с приблизительно того же места (это кстати относиться не только к state-files но и ко всему процессу анализа и я предлгаю сделать это так что изначально все результаты и состояния храняться локально и только при какой то ошибке или принудительной остановке анализа они однозначно выгружаються на сервер (как finally блок)). Чтением занимаеться сам state-manager

4) **Гранулярность Level 4**:
   - Делаем ли отдельные state-files на каждый module/component (Level 4), или Level 4 = только “секция” внутри Level 3 файла?

Ответ: Описал выше. Нет, 4 левела не будет - это будет секция внутри 3 левела

5) **Fail-fast на missing dependency (жёстко)**:
   - Подтверди: если OCR/другая dependency не пришла → `error` и стоп run — это касается **любых** зависимостей?
   - Есть ли зависимости, которые считаем optional (тогда вместо error → empty/skip)?

Ответ: на данный момент если любая dependency не пришла → `error`.

6) **Где хранить DAG в MVP**:
   - Ок ли, что в MVP DAG будет в `docs/component_graph.yaml` (в репе), а позже переносим в БД профилей?

Ответ: да

7) **State update payload (API менеджера)**:
   - Ок ли такой контракт запроса к state-manager:
     - `{run_id, component_name, status, error_code?, artifact_paths?, updated_at}`
   - Нужны ли отдельные события: `checkpoint_set(ocr_ready=true)`?

Ответ: Хороший вопрос. Дело в том что нужно решить как вести прогресс результатов. Это можно делать либо по заверешению компонента, либо разделить компонент на логические части и обновлять state и результаты по блокам внутри компонента. Например в object_detection нет смысла делить на части так как сам компонент работате быстро, да и у него нет логических частей, он просто идет по всем полученым кадрам и находит объекты - то есть его результат и состояние мы сохраняем по завершению компонента. Но есть например компонент cut_detection в котором множество сложных алгоритмов (вроде 6) и каждый из них может выполняться и по 50 секунд, вот в таких случаях есть смысл записывать прогресс и состояние между частями компонента. Что бы это реализовать нужно пройтись по каждому модулю, посмотреть сначала просто на код, примерно разделисть на части, а потом прогнать на тестовом видео и посмотреть на время выполнения отдельных частей - далее уже решать - как финально делить и вести прогресс с состоянием. Запиши эту идею в доки (потом составим план и ты пройдешься по нему).

8) **OCR intervals**:
   - OCR считается по “группам кадров” — что именно считать группой: shot boundaries (cut_detection) или фиксированное окно (например 1 сек)?
   - До появления cut_detection в baseline: используем fixed window?

Ответ: Этот вопрос не относится к глобальным правилам и контрактам. Подобных вопросов можно и нужно задать десятками для каждого модуля. Глобальное правило: пройтись по всем модулям и составить локальные вопросы из которых потом локальные правила и контракты.

9) **Scheduler feedback**:
   - Какие события обязаны уходить наверх: только `component_finished` + duration, или ещё `waiting_started/waiting_ended`, `oom_retry`?

Ответ: Те события которые нужны Scheduler для:
1. Формирования батчей (на разных этапах обработки: длинна видео, кол-во кадров, разрешение, кол-во видео и тд.)
2. Для динамической корректировки значений в чек-листе (фактическое использование памяти и времени отдельного компонента, OOM)

10) **Priority/DAG по этапам (baseline/v1/v2)**:
   - Подтверди: мы ведём **отдельный DAG** для baseline, v1, v2 (три дерева), и выбираем нужный DAG по профилю анализа/режиму?

Ответ: да

---

## Round 5 — итог (зафиксированные решения / decision log)

1) **Имена state-files (принято)**:
- Level 1: `state_level1_global.json`
- Level 2 (DataProcessor/run): `run_state.json`
- Level 3 (per processor): `state_visual.json`, `state_text.json`, `state_audio.json`, `state_segmenter.json`
- **Level 4 отменён**: отдельные файлы на module/component **не делаем**; компоненты пишут состояние **в state-file своего процессора** (через state-manager).

2) **Durability очереди state-manager**:
- Требование: очередь обновлений должна быть **внешней/устойчивой**, чтобы:
  - переживать сбои,
  - уметь восстановиться до последнего стабильного состояния,
  - поддержать retry/resume.
- MVP реализация: append-only журнал событий рядом со state-file (например `state_events.jsonl`) + периодический checkpoint state-file.

3) **Где живут state-files (storage)**:
- State-files живут во **внешнем хранилище**.
- Предложенная runtime политика:
  - по умолчанию всё считается локально (результаты+состояния),
  - при ошибке или принудительной остановке анализа — **обязательная выгрузка** “локального состояния/артефактов” на сервер (как `finally`).
- Чтением state/manifest занимается state-manager.

4) **Fail-fast на missing dependency**:
- На текущем этапе: если **любая dependency** не пришла → `error` и стоп run.

5) **DAG (MVP)**:
- DAG в MVP хранится в `docs/component_graph.yaml` в репозитории; позже мигрируем в БД профилей.

6) **Прогресс внутри компонента (идея)**:
- Прогресс можно вести:
  - либо только “по завершению компонента” (дефолт),
  - либо “по логическим частям” внутри компонента (для длинных/многошаговых, например `cut_detection`).
- Это требует отдельного планирования по модулям: посмотреть код → на тестовом видео померить длительности частей → решить гранулярность событий state.

7) **OCR intervals / локальные вопросы модулей**:
- Уточнение интервалов OCR (shot vs fixed window) — **не глобальное правило**; подобные вопросы решаем локально по модулю через отдельный список “локальных контрактов”.

8) **Scheduler feedback**:
- Репортим наверх всё, что нужно scheduler’у:
  - для формирования батчей (длина видео, количество кадров, resolution, число видео и т.д.),
  - для корректировки чек‑листа (фактическое время/память компонента, OOM).

9) **DAG per stage**:
- Ведём отдельный DAG для baseline/v1/v2 и выбираем нужный DAG по профилю анализа/режиму.

