## TrendFlow — GLOBAL Q&A (Round 1)

Формат работы:
- Я добавляю вопросы в конец файла.
- Ты отвечаешь прямо под каждым вопросом (кратко, но однозначно).
- Если по ответам появляются новые вопросы — я дописываю их ниже отдельным блоком “Round N+1”.

---

### Round 1 — вопросы

#### 1) Продукт, пользователи, UX

- **Q1. Главный MVP пользовательский сценарий**: пользователь даёт ссылку/файл видео → получает прогноз (views/likes) + анализ/рекомендации. Нужны ли разные режимы (например “быстро/дёшево” vs “полный анализ/дорого”) уже в MVP?
  - **A**: Очень хороший и важный вопрос. Расскажу как я вижу это на итоговом сайте (это не финальный контракт а просто мое представление, нужны будут твоеи дороботки и советы). Пользователь заходит в личный кабинет и пополняет счет. Ему начисливаються либо деньги, либо условные еденицы (как это сделано в google colab). Далее пользователь запрашивает анализ и в окне указывает либо ссылку на видео (пока только YouTube) которое мы сами должны скачать и взять мета информацию, либо закачивает свое видео и вводит мета информацию сам в окне. Далее он выбирает фичи которые хочет получить, либо в личном кабинете выбирает уже готовую конфигурацию которую он сделал сам или предоставили мы. В конфигурации указано каки фичи он хочет, но например если там указано что он хочет предсказание, то будут обязательные поля на которых обучалась модель и дополнительные поля (фичи,алгоритмы) которые он просто хочет для анализа. От того какие пункты (фичи) он выберет, будет зависеть стоимость и время обработки, которые динамически высвечиваются у него в окне до начала анализа. Отвечая на твой вопрос: да в mvp нужны “быстро/дёшево” vs “полный анализ/дорого” но реализововть мы это будет через заранее заготовленные конфиги с правильно выбранными алгоритмами, модулями, фичами. В этом рассказе есть ответы не только на вопрос Q1 но и глобальное виденье многих моментов.

- **Q2. Поддерживаемые платформы в проде v1**: только YouTube или сразу закладываем интерфейсы для TikTok/IG (даже если пока заглушки)?
  - **A**: Никаких заглушек. Поскольку пока данные собраны только с ютуба, то и в проде (v1) будет только ютуб.

- **Q3. Вход продукта (прод)**: пользователь загружает файл видео, или даёт URL (YouTube), или оба? Что считаем “источником видео” для дальнейшего кэша и правовых правил?
  - **A**: Есть в ответе на Q1

- **Q4. Выход продукта (прод)**: что именно должен уметь рисовать фронт без LLM (детерминированно из NPZ): список метрик/графиков/карточек (минимум 5–10 пунктов)?
  - **A**: У фронта должна быть возможность нарисовать максимум информации плученой из алгоритмов, а какую именно выбирает сам пользователь на сайте, так что мы реализовываем максимум.

- **Q5. LLM-рендер (MVP)**: подтверждаем, что LLM выдаёт **только текст**, и этот текст обязателен в 2 режимах: “коротко” и “подробно”? (или один режим)
  - **A**: Для MVP нужно сделать что то между, то есть LLM должна дать словесный разбор видео и анализа + дать персональные рекомендации, этот текст должен быть примерно 50-60 предложений (хотя хорошая идея сделать настройку вывода LLM в аккаунте, но базово 50-60 предложений)

#### 2) Репозитории, границы систем, взаимодействие сервисов

- **Q6. Где живёт сайт/бекенд**: в этом же репозитории или отдельный репо? Если отдельный — как называется/где лежит?
  - **A**: сайт/бекенд я еще совсем не делал

- **Q7. Целевая архитектура (MVP)**: какие сервисы обязательны:
  - backend API (auth, runs, billing?),
  - job-queue/worker,
  - DataProcessor (heavy compute),
  - model-serving (Triton),
  - storage (FS/MinIO),
  - DB (Postgres),
  - LLM gateway.
  - **A (список сервисов + “в одном контейнере/в разных”)**: Все что ты перечислил, а как это организовать тут уже ты должнен дать советы и помощь

- **Q8. Кто генерирует `run_id` и `config_hash` в проде**: backend генерирует оба и передаёт в DataProcessor, или DataProcessor сам считает `config_hash` из входного YAML/опций запроса?
  - **A**: Тут нужны твои советы

- **Q9. Политика “повторный запрос того же видео”**: хотим дедуп по `video_id` (heavy compute reuse) всегда, или только если пользователь явно выбрал “использовать кэш”?
  - **A**: Зависит от того сколько видео прожило с момента последнего анализа. Можно задать значение в личном кабинете, например 3 дня и если 3 дня не прошло то береться кэш, а если прошло то заново

#### 3) Контракты данных и строгие правила (что “неподвижно”)

- **Q10. Scope строгого контракта `no-fallback`**:
  - Вариант A: **запрещён везде** (все компоненты/модули обязаны `raise`, если нет `frame_indices` или обязательной зависимости).
  - Вариант B: строго только для **Tier-0 (training schema)**, а Tier-1 может быть best-effort.
  - Вариант C: строго для sampling/deps, но **разрешены альтернативные пайплайны**, если они явно описаны как “не dependency” (пример: `scene_classification` может работать без `core_clip`, если в конфиге так задумано).
  - **A (выбери вариант и 1–2 правила формулировки)**: На этапе разработки и обучения моделей везде строго запрещен fallback, эвристики. Если модуль чего то не может сделать (не хватает данных, зависимостей) он падает с четким описание того где именно произошла ошибка.

- **Q11. NPZ vs JSON в `result_store`**: подтверждаем правило “NPZ = source-of-truth, JSON = только presentation/debug”, и дополнительно:
  - можно ли вообще писать `*.json` артефакты рядом с NPZ (кроме `manifest.json`), или запрещаем и мигрируем legacy?
  - **A**: Тут нужен твой совет, но я думаю запретить json кроме манифестов и все артифакты (фичи) писать в npz, а переводить в json только когда отдаем на фронт для presentation/debug.

- **Q12. Единая структура storage**: фиксируем окончательно:
  - `result_store/<platform_id>/<video_id>/<run_id>/<component_name>/*.npz`
  - `result_store/<platform_id>/<video_id>/<run_id>/manifest.json`
  - **A (да/нет + если нет — твой вариант)**: Реши сам, но мне эта нравиться

- **Q13. Состав “run identity” (обязательные поля)**: оставляем минимум как в валидаторе (`platform_id, video_id, run_id, config_hash, sampling_policy_version`) или добавляем ещё `dataprocessor_version` как обязательный?
  - **A**: Реши сам

- **Q14. Aliases/совместимость имён компонентов**: в коде ещё есть alias folder mapping (например `core_depth_midas` ↔ `depth_midas`). Утверждаем план:
  - “каноничные имена везде” + “compat слой только на чтение старого” + “потом удалить”.
  - **A (да/нет + дедлайн/условие удаления)**: да. Удалить как можно быстрее

- **Q15. “Valid empty outputs”**: фиксируем единый список стандартных `empty_reason` (пример: `no_faces_in_video`, `audio_missing_or_extract_failed`, `no_text_available`, `ocr_disabled_by_policy`)?
  - **A**: Тут нужны твои советы, нужно подумать

#### 4) Segmenter / sampling / frames_dir

- **Q16. Analysis timeline**: какие дефолты фиксируем для Segmenter на прод:
  - `analysis_fps` (например 12/15/24),
  - `analysis_width/height` (например 256/320/512),
  - max duration (сейчас 20 мин),
  - и как обрабатываем входные 60fps/4K.
  - **A**: Реши какие дефолты будут хороши для MVP+ продукта. Максимальная длительность точно 20 мин. По разрешению мы не обрабатываем более FullHD

- **Q17. Retention для `frames_dir`**: в проде храним union-кадры после прогона?
  - Вариант A: удаляем сразу после вычисления NPZ (минимум риска/дешевле).
  - Вариант B: храним N дней для дебага/повторного рендера.
  - Вариант C: храним только для платных пользователей/по флагу.
  - **A**: Вариант B - 7 дней

#### 5) Audio/Text processors — “fallbacks” и тяжёлые зависимости

- **Q18. AudioProcessor fallbacks**: в документах AudioProcessor описаны fallbacks по зависимостям (Essentia/pyloudnorm/SpeechBrain/…).
  - Разрешаем ли “fallback на более простой алгоритм”, если зависимость/модель недоступна?
  - Или это считается нарушением `no-fallback` (и тогда компонент должен `raise`/ставить status=error)?
  - **A (правило + только для Tier-1 или везде)**: AudioProcessor еще не адаптирован под новые контракты и правила. это считается нарушением `no-fallback`

- **Q19. TextProcessor embeddings (GPU-heavy)**: включаем ли эмбеддинги в Tier-0 training schema или оставляем как optional (Tier-1) на MVP?
  - **A**: Включаем в Tier-0

#### 6) БД, кэш, хранилище

- **Q20. Где храним NPZ в проде**: стартуем с локального диска или сразу делаем S3-compatible (MinIO)? (и где будет жить MinIO — на том же сервере?)
  - **A**: Предложи сам

- **Q21. Artifact index (в БД)**: какие минимальные таблицы/сущности нужны в MVP:
  - users,
  - videos,
  - runs,
  - components,
  - render_cache (LLM outputs),
  - billing (опционально).
  - **A (минимальный список)**: Реши сам, посоветуй

- **Q22. Политика кэша heavy compute**: “последние 10k видео” — это hard cap по уникальным `video_id`.
  - Как выбираем, что выкидывать (LRU по запросам, TTL, size-based)?
  - **A**: по дате анализа

#### 7) Политики, право, приватность (инженерно-формализуемые решения)

- **Q23. Raw retention (видео/комменты/OCR)**: подтверждаем дефолт:
  - `retain_raw_ocr_text=false`, `retain_raw_comments=false`,
  - raw разрешён только после OAuth-верификации владельца канала,
  - и при этом всё равно есть `hard_cap_days`.
  - **A (подтверждаешь? какое значение `hard_cap_days` берём на MVP: 30/90/другое)**: 60 дней

- **Q24. “Право на удаление”**: нужен ли в продукте MVP механизм: пользователь/правообладатель просит удалить данные по `video_id` → мы удаляем артефакты/кэш/LLM-рендер?
  - **A**: Да, все удаляем

- **Q25. Политика логов и PII**: разрешаем ли писать в логи raw тексты/комменты/части транскрипта? (рекомендация: запрещать по умолчанию)
  - **A**: Реши сам

#### 8) Эксплуатация и надежность

- **Q26. Required vs optional компоненты**: фиксируем Tier-0 список (10 компонентов) как required (fail-fast), остальное optional (best-effort). Нужно ли это уже сейчас формально описать в конфиге (YAML) как `required_components[]`?
  - **A**: Tier-0 и Tier-1 это так или иначе моменты разработки и обучения моделей, а тут нет best-effort. Так что у нас все компоненты обязательны просто какие то идут в Tier-0, а какие то потом в полный Tier-1

- **Q27. Поведение при частичных ошибках**: если один audio extractor упал, но остальные ок — run считается ok/partial/error? (как это отражаем в UI)
  - **A**: Если этот экстрактор не выдает данные для модели, то ок. Но тут нужны твои советы.

- **Q28. Observability MVP**: что обязательно собираем в `manifest.json` и/или БД:
  - timings per component,
  - device used,
  - GPU mem,
  - peak RAM,
  - empty_reason/error.
  - **A (минимум 5 полей)**: Реши сам

#### 9) Процесс разработки (контракты, схемы, миграции)

- **Q29. Источник правды для схем**: подтверждаем “двойной слой”:
  - `SCHEMA.md` (human) + `VisualProcessor/schemas/*.json` (machine),
  - и CI правило: “если поменяли schema в коде — обновили schemas/*.json”.
  - **A**: Да

- **Q30. Политика версионирования**: что именно бампим при изменениях:
  - `schema_version` (обязательно при shape/keys),
  - `producer_version` (при изменении алгоритма без смены схемы),
  - `sampling_policy_version` (при изменении Segmenter policy),
  - `dataprocessor_version` (релиз всего пайплайна).
  - **A (подтверди/поправь + где храним `dataprocessor_version`)**: Реши сам

---

### (зарезервировано) Round 2 — добавим после твоих ответов

---

### Round 1 — зафиксировано (полуфинальные решения)

- **Платформа v1**: только YouTube (`platform_id="youtube"`).
- **Профили анализа (configs)**: пользователь выбирает профиль; стоимость/время зависят от включённых фич/модулей.
- **Прогноз → обязательный набор фичей**: если профиль включает prediction, то компоненты training schema обязаны быть включены.
- **LLM**: только текст; дефолт ~50–60 предложений (позже можно дать настройку в аккаунте).
- **No-fallback (dev/train)**: в разработке/обучении fallback/эвристики запрещены; при нехватке данных/зависимостей компонент обязан падать с понятной ошибкой.
- **Артефакты**: NPZ — source-of-truth; в `result_store` запрещаем `*.json` кроме `manifest.json`.
- **Retention**:
  - `frames_dir` (union кадры) — 7 дней,
  - raw OCR/comments (если включены и разрешены) — hard cap 60 дней.
- **Delete request**: по запросу удаляем данные по `video_id` (артефакты/кэш/рендер).

### Round 2 — вопросы (только то, что осталось незафиксированным)

- **Q31. `run_id` и `config_hash` (прод)**: предлагаю финально:
  - `run_id` генерирует backend,
  - `config_hash` считает backend детерминированно из “profile config” (включённые компоненты+параметры+версии policy) и передаёт в DataProcessor,
  - DataProcessor не “придумывает” config_hash сам.
  - **A (да/нет, если нет — твой вариант)**: Да

- **Q32. “Качество vs best-effort” (прод)**: предлагаю правило:
  - все компоненты, включённые в профиль анализа, считаются required (fail-fast),
  - optional/best-effort разрешён только если компонент явно помечен optional в профиле.
  - **A**: Да

- **Q33. `analysis_fps` и resize defaults**: предлагаю для MVP:
  - `analysis_fps=12`,
  - `analysis_height=320` (width по аспекту),
  - clamp input до 1080p на входе (если больше — downscale до 1080p до анализа).
  - **A (ок/не ок, если не ок — какие значения)**: ок (напомниаю что нам важно качество)

- **Q34. Empty reasons (каноничный словарь)**: предлагаю стартовый набор:
  - `audio_missing_or_extract_failed`
  - `no_faces_in_video`
  - `no_text_available`
  - `ocr_disabled_by_policy`
  - `comments_missing_or_disabled`
  - `video_too_short`
  - `video_too_long`
  - `dependency_missing`
  - **A (ок/не ок, что добавить/убрать)**: Да

- **Q35. Хранилище NPZ в MVP проде**: предлагаю:
  - dev: локальный диск,
  - prod: MinIO (S3-compatible) на нашем сервере (бесплатно, потом миграция на S3).
  - **A**: Да

- **Q36. DB schema MVP (artifact index)**: предлагаю минимум таблиц:
  - `users`, `videos`, `runs`, `run_components`, `artifacts`, `render_cache`, `billing_ledger` (если будут кредиты).
  - **A (ок/не ок, что убрать/добавить)**: ок

- **Q37. Логи и PII**: предлагаю правило по умолчанию:
  - в логи не пишем raw текст/комменты/транскрипт; только длины, счётчики, хэши, статусы.
  - raw допускается только в локальном dev при явном флаге.
  - **A**: ок

- **Q38. Partial failures**: если упал компонент, который не участвует в prediction schema, считаем run:
  - `status="ok"` + component_status="error" + предупреждение в UI,
  - prediction всё равно выдаём (если required компоненты ok).
  - **A**: да

- **Q39. Observability MVP**: предлагаю минимальные поля в `manifest` per component:
  - `status`, `started_at`, `finished_at`, `duration_ms`, `device_used`, `error`, `notes`, `schema_version`, `producer_version`
  - **A**: да

- **Q40. `dataprocessor_version`**: предлагаю сделать обязательным в `manifest.run` и в `meta` каждого NPZ (в baseline может быть `unknown`).
  - **A**: да

---

### Round 2 — зафиксировано (полуфинальные решения)

- **Run identity (прод)**: `run_id` и `config_hash` генерирует backend; DataProcessor только прокидывает их во все подпроцессоры.
- **Required vs optional (прод)**: все компоненты в профиле анализа = required (fail-fast); optional только если явно помечено в профиле.
- **Analysis timeline defaults**: `analysis_fps=12`, `analysis_height=320` (width по аспекту), clamp входного видео до 1080p, max duration 20 мин.
- **Empty reasons словарь**: каноничный набор значений (`audio_missing_or_extract_failed`, `no_faces_in_video`, `no_text_available`, `ocr_disabled_by_policy`, `comments_missing_or_disabled`, `video_too_short`, `video_too_long`, `dependency_missing`).
- **Хранилище**: prod = MinIO (S3-compatible) на нашем сервере.
- **DB schema MVP**: `users`, `videos`, `runs`, `run_components`, `artifacts`, `render_cache`, `billing_ledger` (опционально).
- **Логи без PII**: по умолчанию raw тексты/комменты/транскрипт не пишем в логи; только длины/счётчики/хэши/статусы.
- **Partial failures**: если упал non-required компонент, run = `status="ok"` + component_status="error" + предупреждение в UI; prediction всё равно выдаём.
- **Observability**: минимальные поля в manifest per component: `status`, `started_at`, `finished_at`, `duration_ms`, `device_used`, `error`, `notes`, `schema_version`, `producer_version`.
- **dataprocessor_version**: обязателен в `manifest.run` и в `meta` каждого NPZ.

---

### Round 3 — вопросы (глубокие, практические, прод-фокус)

#### 10) Backend ↔ DataProcessor коммуникация и API

- **Q41. Протокол взаимодействия backend ↔ DataProcessor (прод)**: как backend передаёт задачу на обработку:
  - Вариант A: REST API (DataProcessor слушает HTTP, принимает POST /process с `run_id/config/video_url/path`),
  - Вариант B: через очередь (backend кладёт задачу в queue, DataProcessor worker подписывается),
  - Вариант C: gRPC/другой протокол.
  - **A (выбери вариант + краткое обоснование)**: Реши сам, нужен твой совет
  - **Рекомендация**: **Вариант B (Queue-based)** — оптимален для продакшена:
    - Масштабируемость: несколько worker'ов могут читать из одной очереди параллельно
    - Надёжность: задачи не теряются при падении worker'а (persistent queue: Redis/RabbitMQ)
    - Декoupling: backend и worker независимы, можно обновлять отдельно
    - Retry: встроенная поддержка retry на уровне очереди
    - Мониторинг: легко отслеживать длину очереди, время ожидания
    - Для MVP: Redis + RQ (Python) или Celery — простые и надёжные варианты
    - Синхронный режим (Q43): можно добавить отдельный HTTP endpoint `/process/sync` для тестов, но основной путь — queue

- **Q42. Формат payload запроса на обработку**: что именно передаёт backend в DataProcessor:
  - `run_id`, `video_id`, `platform_id`, `config_hash`, `sampling_policy_version`, `dataprocessor_version` (run identity),
  - `video_url` (YouTube) или `video_path` (upload), `meta_json` (если upload),
  - `profile_config` (какие компоненты включены) или только `config_hash` (конфиг уже закэширован),
  - `user_id` (для аудита),
  - `priority` / `deadline` (опционально).
  - **A (список обязательных полей + опциональные)**: реши сам
  - **Рекомендация**: **Обязательные поля**:
    - `run_id` (UUID, генерирует backend)
    - `video_id` (каноничный ID)
    - `platform_id` ("youtube")
    - `config_hash` (детерминированный хэш профиля)
    - `sampling_policy_version`, `dataprocessor_version`
    - `video_source`: `{"type": "youtube_url", "url": "..."}` или `{"type": "upload", "path": "...", "meta": {...}}`
    - `user_id` (для аудита и биллинга)
    - **Опциональные**:
    - `profile_config` (полный JSON профиля) — передаём для первого запуска, потом можно кэшировать по `config_hash`
    - `priority` (int, для будущей приоритизации)
    - `callback_url` (webhook для уведомлений, опционально)
    - `metadata` (любые дополнительные данные для аудита)

- **Q43. Синхронный vs асинхронный режим**: DataProcessor обрабатывает задачи:
  - только асинхронно (task в queue → worker обрабатывает → callback/status poll),
  - или поддерживает оба режима (синхронный для быстрых тестов, асинхронный для продакшена)?
  - **A**: поддерживает оба режима
  - **Рекомендация**: 
    - **Асинхронный (основной)**: через queue, worker обрабатывает задачи
    - **Синхронный (для тестов/dev)**: HTTP endpoint `POST /process/sync` с timeout (например, 5 минут)
    - Синхронный режим полезен для:
      - быстрой отладки в dev
      - smoke-тестов
      - небольших видео (< 1 минуты) для демо
    - В проде: только асинхронный через queue (синхронный отключён или требует специального флага)

- **Q44. Статус прогресса (прод)**: как backend/UI узнаёт о прогрессе обработки:
  - polling (backend периодически проверяет статус run в БД/manifest),
  - webhooks/callbacks (DataProcessor отправляет события в backend),
  - или через очередь (статусы как события в queue).
  - **A**: реши сам как будет лучше
  - **Рекомендация**: **Гибридный подход** (лучший баланс):
    - **Polling (основной)**: backend/UI опрашивает `/api/runs/{run_id}/status` каждые 2-5 секунд
      - Простота реализации
      - Не требует сложной инфраструктуры
      - Работает через стандартный REST API
    - **Webhooks (опционально)**: DataProcessor может отправлять события в backend через webhook (если указан `callback_url`)
      - Для real-time обновлений (если нужно)
      - Не критично для MVP
    - **Статусы в БД**: worker обновляет статус в БД после каждого этапа (Segmenter → Audio → Text → Visual → Render)
    - **Manifest.json**: также обновляется атомарно, можно читать напрямую из MinIO для восстановления
    - Для MVP: polling достаточно, webhooks можно добавить позже

#### 11) Billing, кредиты, стоимость

- **Q45. Единица биллинга**: что считается “единицей списания”:
  - “1 анализ” (независимо от сложности профиля),
  - “1 компонент” (списываем за каждый успешный компонент отдельно),
  - “время обработки × профиль” (более сложный профиль = дороже),
  - “комбинированная формула” (базовая стоимость + премиум компоненты).
  - **A (выбери вариант + краткое обоснование)**: перед формированием стоимости мы должны четко понимать сколько требуеться ресурсов и времени для получения конкретной фичи при всех возможных входах (например размерах кадра). Например пользователь пополнил на 500 рублей и ему начислилось 500 едениц. Он захотел получить предсказание (например 100 едениц при его разрешении и длительности видео) + одну доп. фичу (например среднее значение ембединга по кадру, например 3 еденицы при его разрешении и длительности видео) для своего видео с разрешением HD, далее мы должны знать ресурсозатратность и времязатратность всех алгоритмов которые выдают фичи для подели для предсказания + ресурсы и время на получения его доп. фичи для его случая, то есть кадры в размере HD. Жду твои советы и предложения
  - **Рекомендация**: **Комбинированная формула с ресурсной моделью**:
    - **Базовая структура ценообразования**:
      ```
      cost_component = base_cost + (compute_time × compute_rate) + (gpu_time × gpu_rate) + markup
      ```
    - **Параметры для каждого компонента** (храним в БД/конфиге):
      - `base_cost`: фиксированная базовая стоимость (например, 0.1 единиц)
      - `compute_time_per_frame`: среднее время обработки 1 кадра (CPU, секунды)
      - `gpu_time_per_frame`: среднее время на GPU (если требуется)
      - `scaling_factor_resolution`: коэффициент масштабирования по разрешению (HD=1.0, 4K=2.5)
      - `scaling_factor_duration`: коэффициент по длительности (линейный или логарифмический)
      - `markup_percent`: наценка (например, 20%)
    - **Пример расчёта**:
      - Tempo extractor (CPU-only, быстрый): `0.1 + (0.001 × frames × 0.01) + 0.2 = ~0.5 единиц`
      - Face emotion (GPU, тяжёлый): `0.1 + (0.05 × frames × 0.5) + (0.1 × frames × 2.0) + 0.3 = ~15 единиц`
    - **Сбор метрик**: после каждого run записываем реальное время/ресурсы в `manifest.json` → используем для калибровки модели
    - **MVP упрощение**: можно начать с фиксированных цен за компонент (без детального расчёта), но собирать метрики для будущей калибровки

- **Q46. Когда списываем кредиты**: 
  - сразу при создании run (до начала обработки),
  - после успешного завершения (если run failed → возврат),
  - по факту успешных компонентов (partial failures = частичное списание).
  - **A**: Списываем только после успешного завершения по факту успешных компонентов
  - **Рекомендация**: **Частичное списание (best practice)**:
    - **Резервирование**: при создании run резервируем максимальную сумму (по оценке)
    - **Списание**: после завершения списываем только за успешные компоненты
    - **Возврат**: разница возвращается на баланс пользователя
    - **Partial failures**: если упал non-required компонент → списываем только за успешные
    - **Полный failure**: если упал required компонент → ничего не списываем (или минимальная плата за попытку, например 0.1 единиц)
    - **Аудит**: все транзакции в `billing_ledger` с привязкой к `run_id` и `component_name`

- **Q47. Ценообразование (MVP)**: предлагаю для старта:
  - “базовый профиль” (prediction + минимум фичей) = 1 кредит,
  - “полный профиль” (prediction + все аналитические компоненты) = 3 кредита,
  - кастомный профиль = базовая стоимость + коэффициенты за каждый дополнительный компонент.
  - **A (ок/не ок, твои значения)**: я уже объяснил в ответе на Q45. Подробнее: тут в ценообразовании нужно понимать сколько ресурсов сервера будет тратить каждый алгоритм для конкретного случая. Например извлечение темпа из аудио достаточно быстрый процесс, не требует GPU и дешево нам обойдеться даже при длинном видео, то есть его стоимость можно рассчитать как чистые затраты электроэнергии сервера + процент (например, 0.5 едениц). А например Анализ лиц на кадре дорогой так как нуждаеться в GPU и тратит больше времени и электроэнергии сервера, поэтому нам обойдеться дороже + больший процент (например 15 едениц).
  - **Рекомендация**: **Структура прайс-листа (MVP)**:
    - **Таблица `component_pricing` в БД**:
      ```sql
      component_name | base_cost | cpu_cost_per_sec | gpu_cost_per_sec | resolution_factor | duration_factor
      tempo_extractor | 0.1 | 0.001 | 0 | 1.0 | 0.5
      face_emotion | 0.5 | 0.01 | 0.1 | 1.5 | 1.0
      ```
    - **Категории компонентов** (для упрощения MVP):
      - **Tier-0 (required для prediction)**: фиксированная базовая стоимость (например, 50 единиц за весь набор)
      - **Tier-1 (опциональные)**: индивидуальная стоимость каждого
    - **Формула для оценки**:
      ```
      estimate = sum(component.base_cost × resolution_factor × duration_factor) × (1 + markup)
      ```
    - **Калибровка**: после 100-1000 runs собираем реальные метрики и обновляем прайс-лист

- **Q48. Оценка стоимости до запуска**: UI показывает оценку стоимости до начала анализа. Кто считает:
  - backend имеет “прайс-лист” компонентов и считает локально,
  - DataProcessor предоставляет эндпоинт “estimate cost” (принимает profile_config, возвращает оценку),
  - или правило простое (1 кредит = 1 компонент, оценка = количество компонентов).
  - **A**: backend имеет “прайс-лист”. Я пока не знаю как считать в плане кредитов, но давай пока за основу возьмем 1 рубль = 1 еденице. В ответе на Q47 подробнее рассписано. Давай свои рекомендации по 11 пункту.
  - **Рекомендация**: **Backend-расчёт (правильный выбор)**:
    - Backend имеет таблицу `component_pricing` в БД
    - При создании run backend:
      1. Читает `profile_config` (какие компоненты включены)
      2. Получает параметры видео (разрешение, длительность) от пользователя или из мета
      3. Рассчитывает стоимость по формуле из Q47
      4. Показывает оценку пользователю до подтверждения
    - **Преимущества**:
      - Быстро (не нужно ждать DataProcessor)
      - Можно кэшировать расчёты для популярных профилей
      - Backend контролирует ценообразование (можно менять без деплоя DataProcessor)
    - **1 рубль = 1 единица**: хорошая стартовая точка, но нужно учесть реальные затраты на инфраструктуру для калибровки
    - **Валидация**: после завершения run можно сравнить оценку с реальной стоимостью для улучшения модели

#### 12) Error handling, retry, timeouts (прод)

- **Q49. Таймауты на уровне оркестрации**: предлагаю фиксировать:
  - общий timeout на весь run (например, 2 часа для видео до 20 мин),
  - timeout per component (например, 30 минут на компонент),
  - timeout на Segmenter (например, 15 минут на скачивание/сегментацию).
  - **A (ок/не ок, какие значения)**: Давай отложим этот вопрос до момета пока не доделаем DataProcessor.
  - **Рекомендация**: **Отложить — правильное решение**. После baseline можно зафиксировать:
    - Общий timeout: `max(2 часа, video_duration × 6)` (6x реального времени как запас)
    - Timeout per component: `30 минут` (можно настраивать per component в конфиге)
    - Segmenter timeout: `15 минут` (скачивание + сегментация)
    - **Важно**: таймауты должны быть конфигурируемыми через профиль анализа

- **Q50. Retry политика (прод)**: если компонент упал:
  - не ретраим (fail-fast, лучше быстро упасть и показать ошибку),
  - ретраим N раз с backoff (например, 2–3 попытки),
  - ретраим только “transient errors” (network/timeout/OOM), но не логические ошибки (missing dependency).
  - **A (правило + какие ошибки ретраим, какие нет)**: да
  - **Рекомендация**: **Retry только transient errors**:
    - **Ретраим (2-3 попытки с exponential backoff)**:
      - Network errors (connection timeout, DNS failure)
      - Timeout errors (component превысил timeout)
      - OOM (Out of Memory) — если компонент поддерживает уменьшение batch_size
      - Triton unavailable (503 Service Unavailable)
    - **НЕ ретраим (fail-fast)**:
      - Missing dependency (frame_indices отсутствуют)
      - Invalid input (повреждённое видео, неподдерживаемый формат)
      - Logic errors (алгоритм вернул ошибку валидации)
      - Authentication errors (неверный API key)
    - **Реализация**: использовать библиотеку `tenacity` (Python) или встроенные retry в queue (Celery/RQ)

- **Q51. Обработка network errors (YouTube download, Triton, LLM gateway)**: предлагаю:
  - YouTube download: ретраим 3 раза с экспоненциальным backoff (1s, 2s, 4s),
  - Triton: ретраим 2 раза (transient errors), если модель недоступна → fail-fast,
  - LLM gateway: ретраим 2 раза, если rate limit → возвращаем ошибку пользователю (не ретраим бесконечно).
  - **A (ок/не ок, твои правила)**: да
  - **Рекомендация**: **Правила подтверждаю, уточнения**:
    - **YouTube download**: 
      - 3 попытки с backoff: `[1s, 2s, 4s]` — ок
      - Дополнительно: проверять размер файла после скачивания (если < 1MB → вероятно ошибка)
    - **Triton**: 
      - 2 попытки для transient errors (503, 504, connection timeout)
      - Если модель не найдена (404) → fail-fast (не ретраим)
      - Если authentication error (401) → fail-fast
    - **LLM gateway**:
      - 2 попытки для network/timeout errors
      - Rate limit (429): возвращаем ошибку пользователю с сообщением "Сервис перегружен, попробуйте позже"
      - Не ретраим при 4xx errors (bad request, auth errors)

- **Q52. OOM (Out of Memory) handling**: если компонент упал с OOM:
  - fail-fast (run = error, пользователь видит ошибку),
  - автоматически перезапускаем с уменьшенным batch_size/chunk_size (если компонент это поддерживает),
  - или помечаем run как “требует больше ресурсов” и предлагаем пользователю повторить на другом сервере.
  - **A**: автоматически перезапускаем с уменьшенным batch_size/chunk_size (если компонент это поддерживает), НО вообще такого не должно быть в проде.
  - **Рекомендация**: **OOM handling с fallback**:
    - **Первый уровень**: компоненты должны иметь конфигурируемый `batch_size`/`chunk_size`
    - **При OOM**: автоматически уменьшаем batch_size в 2 раза и ретраим (максимум 2 попытки)
    - **Если всё равно OOM**: помечаем run как `status="error"`, `error="out_of_memory"`, `notes="requires_more_resources"`
    - **Мониторинг**: логируем все OOM случаи для анализа (какие компоненты/видео вызывают проблемы)
    - **Профилактика**: в проде должны быть лимиты на размер видео/разрешение, чтобы минимизировать OOM
    - **Альтернатива**: можно добавить "lightweight mode" для больших видео (автоматически уменьшаем resolution/batch_size)

#### 13) Edge cases и ограничения

- **Q53. Видео > 20 минут**: что делаем, если пользователь загрузил видео длиннее лимита:
  - отказываемся обрабатывать (error: `video_too_long`),
  - обрабатываем только первые 20 минут,
  - обрабатываем полностью, но с предупреждением о возможном увеличении стоимости/времени.
  - **A**: отказываемся обрабатывать (error: `video_too_long`)
  - **Рекомендация**: **Валидация на входе**:
    - Backend проверяет длительность видео ДО создания run (из мета YouTube или пользовательского ввода)
    - Если > 20 минут → возвращаем ошибку сразу (не создаём run, не списываем кредиты)
    - Сообщение пользователю: "Видео слишком длинное (максимум 20 минут). Пожалуйста, обрежьте видео или выберите другой файл."
    - **Будущее**: можно добавить опцию "обработать первые 20 минут" (но это требует изменения контракта)

- **Q54. Повреждённые/некорректные видео файлы**: если Segmenter/ffmpeg не смог прочитать видео:
  - run = error с понятным сообщением (`video_file_corrupted`),
  - возвращаем кредиты (если списали заранее),
  - или пытаемся исправить/конвертировать автоматически (если возможно).
  - **A**: пытаемся исправить/конвертировать автоматически (если возможно) (главное без потери качества). Кредиты мы заранее не списываем. Твои советы как можем исправлять?
  - **Рекомендация**: **Автоматическое исправление через ffmpeg**:
    - **Шаг 1**: пытаемся прочитать видео через ffmpeg с опцией `-err_detect ignore_err` (игнорирует мелкие ошибки)
    - **Шаг 2**: если не получилось → пытаемся перекодировать: `ffmpeg -i input -c:v libx264 -c:a aac -preset slow -crf 18 output.mp4`
      - `-preset slow`: лучшее качество (медленнее, но без потерь)
      - `-crf 18`: практически lossless (CRF 0 = полностью lossless, но файл огромный)
    - **Шаг 3**: если перекодирование не помогло → `error="video_file_corrupted"`, отказываемся обрабатывать
    - **Логирование**: записываем все попытки исправления в `manifest.json` для анализа
    - **Timeout**: на исправление даём максимум 5 минут (если дольше → считаем файл некорректным)
    - **Качество**: `-crf 18` даёт визуально идентичное качество, но файл может быть немного больше оригинала

- **Q55. Видео без звука**: предлагаю:
  - AudioProcessor компоненты получают `status="empty"`, `empty_reason="audio_missing_or_extract_failed"`,
  - run продолжается (видео компоненты обрабатываются),
  - если audio required для prediction → run = error.
  - **A**: Да

- **Q56. Видео без кадров / очень короткие (< 1 секунды)**: что делаем:
  - отказываемся (`video_too_short`),
  - обрабатываем как есть (но многие компоненты вернут empty),
  - или применяем специальную логику для very-short видео.
  - **A**: отказываемся (`video_too_short`). Минимальная длинна = 5 сек.
  - **Рекомендация**: **Валидация на входе**:
    - Backend проверяет длительность ДО создания run
    - Если < 5 секунд → ошибка сразу (не создаём run)
    - Сообщение: "Видео слишком короткое (минимум 5 секунд)"
    - **Технически**: можно обработать и < 5 сек, но большинство алгоритмов требуют минимум несколько кадров для анализа

#### 14) Video download и preprocessing

- **Q57. YouTube download (прод)**: как скачиваем:
  - используем `yt-dlp` (как в BatchRunner),
  - формат: best quality до 1080p, или фиксируем формат (например, `bestvideo[height<=1080]+bestaudio`),
  - timeout на скачивание (например, 5 минут),
  - ретраи при network errors (3 попытки).
  - **A (ок/не ок, какие параметры yt-dlp, timeout, retry)**: yt_dlp вроде норм для прода (я на нем качал 100к видео и было хорошо). Формат выбирает пользователь с нашими подсказками о скорости и качестве. timeout динамичсекий и зависит от разрешения и длительности, потом точно определим.  ретраи при network errors (3 попытки)
  - **Рекомендация**: **yt-dlp для прода — подтверждаю**:
    - **Параметры yt-dlp**:
      ```python
      yt_dlp_options = {
          'format': 'bestvideo[height<=1080]+bestaudio/best[height<=1080]',  # дефолт до 1080p
          'outtmpl': '%(id)s.%(ext)s',
          'no_warnings': False,
          'extract_flat': False,
      }
      ```
    - **Пользовательский выбор формата**: хорошая идея, но для MVP можно начать с дефолта (1080p)
    - **Timeout**: формула `timeout = max(60, video_duration_sec × 0.1 + 120)` (минимум 1 минута, плюс запас)
    - **Retry**: 3 попытки с backoff `[5s, 15s, 30s]` (для скачивания нужны более длинные интервалы)
    - **Мониторинг**: логируем время скачивания для калибровки timeout

- **Q58. Preprocessing перед Segmenter**: нужно ли делать:
  - конвертацию формата (если скачали не MP4),
  - downscale до 1080p (если видео 4K),
  - или Segmenter сам обрабатывает любой формат/resolution.
  - **A**: Нужно внести в Segmenter функционал предобработки. Все как ты сказал главное без потери качества на обработке.
  - **Рекомендация**: **Preprocessing в Segmenter**:
    - **Конвертация формата**: если входной файл не MP4 → конвертируем через ffmpeg: `ffmpeg -i input -c:v copy -c:a copy output.mp4` (без перекодирования, если кодеки поддерживаются)
    - **Downscale до 1080p**: если разрешение > 1080p → `ffmpeg -i input -vf "scale=-2:1080:flags=lanczos" -c:a copy output.mp4`
      - `lanczos`: высококачественный алгоритм масштабирования (практически без потерь)
    - **Без потери качества**: используем `-crf 18` или `-c:v copy` (если возможно)
    - **Логирование**: записываем все операции preprocessing в `manifest.json` (что было сделано, исходное разрешение/формат)
    - **Кэширование**: обработанный файл можно сохранить временно (если планируется повторная обработка)

- **Q59. Временное хранилище для скачанных видео**: где храним файл между download и Segmenter:
  - в MinIO/S3 как временный объект (TTL, например, 1 день),
  - на локальном диске worker'а (удаляем после обработки),
  - или сразу передаём потоком в Segmenter (без сохранения на диск).
  - **A**: Посоветуй ты как лучше.
  - **Рекомендация**: **Локальный диск worker'а (оптимально для MVP)**:
    - **Вариант**: временный файл на локальном диске worker'а (`/tmp/trendflow/{run_id}/video.mp4`)
    - **Преимущества**:
      - Быстро (не нужно загружать/скачивать из MinIO)
      - Дешево (нет трафика в MinIO)
      - Простота реализации
    - **Очистка**: удаляем файл сразу после Segmenter (или через 1 час TTL)
    - **Альтернатива (для будущего)**: если worker'ы распределены и могут падать → можно сохранять в MinIO с TTL 1 день, но для MVP это избыточно
    - **Исключение**: если видео очень большое (> 5GB) → можно использовать MinIO для экономии места на диске worker'а

#### 15) Мониторинг, health checks, alerting

- **Q60. Health check endpoints**: какие эндпоинты нужны для каждого сервиса:
  - `/health` (базовый: сервис запущен),
  - `/health/ready` (готов принимать запросы: GPU доступен, Triton подключён, MinIO доступен),
  - `/health/live` (liveness: процесс не завис).
  - **A (список обязательных эндпоинтов)**: Да
  - **Рекомендация**: **Стандартные health checks**:
    - `/health` (readiness): проверяет, что сервис запущен и готов принимать запросы
      - Backend: БД доступна, очередь доступна
      - Worker: очередь доступна, MinIO доступен, Triton доступен (если требуется)
      - Triton: модели загружены
    - `/health/live` (liveness): проверяет, что процесс не завис (просто возвращает 200)
    - **Реализация**: использовать библиотеку `healthcheck` (Python) или простой endpoint
    - **Мониторинг**: Kubernetes/Docker будут опрашивать эти endpoints для автоматического перезапуска

- **Q61. Метрики для мониторинга (MVP)**: что обязательно собираем:
  - throughput (обработано видео за час),
  - success rate (доля успешных runs),
  - среднее время обработки per component,
  - GPU utilization,
  - очередь задач (длина очереди, время ожидания),
  - ошибки (частота по типам).
  - **A (минимум 5 метрик + где храним: Prometheus/Grafana/другое)**: Все будет через Grafana + Prometheus, но конкретно определимся чуть позже.
  - **Рекомендация**: **Prometheus + Grafana — правильный выбор**:
    - **Метрики для сбора** (минимум):
      1. `runs_total` (counter): общее количество запущенных runs
      2. `runs_success_rate` (gauge): доля успешных runs за последний час
      3. `component_duration_seconds` (histogram): время обработки per component
      4. `gpu_utilization_percent` (gauge): использование GPU
      5. `queue_length` (gauge): длина очереди задач
      6. `errors_total` (counter by error_type): количество ошибок по типам
    - **Экспорт метрик**: использовать `prometheus_client` (Python) для экспорта метрик
    - **Дашборды Grafana**: создать дашборды для визуализации метрик
    - **Алерты**: настраиваем через Prometheus Alertmanager (см. Q62)

- **Q62. Alerting (MVP)**: на что алертим:
  - сервис недоступен (health check failed),
  - очередь переполнена (> N задач),
  - success rate упал ниже порога (например, < 80%),
  - среднее время обработки выросло сильно (например, > 2x от baseline),
  - GPU OOM часто (например, > 10% runs).
  - **A (список критичных алертов для MVP)**: Решим когда определимся с метриками
  - **Рекомендация**: **Критичные алерты (после настройки метрик)**:
    1. **Сервис недоступен**: health check failed > 2 минуты → критично
    2. **Очередь переполнена**: `queue_length > 100` → предупреждение
    3. **Success rate упал**: `runs_success_rate < 80%` за последний час → предупреждение
    4. **GPU OOM часто**: `errors_total{error_type="out_of_memory"} > 10%` от всех runs → предупреждение
    5. **Среднее время обработки выросло**: `component_duration_seconds > baseline × 2` → информационный алерт
    - **Каналы уведомлений**: email/Slack/Telegram (настраивается в Alertmanager)

#### 16) Масштабирование и deployment

- **Q63. Горизонтальное масштабирование DataProcessor workers**: предлагаю:
  - несколько worker'ов читают из одной queue (parallel processing),
  - каждый worker может обрабатывать 1 видео за раз (или N параллельно, если есть несколько GPU),
  - масштабирование: добавляем worker'ы при росте очереди (auto-scaling или manual).
  - **A (ок/не ок, сколько видео параллельно на 1 worker)**: ок
  - **Рекомендация**: **Горизонтальное масштабирование**:
    - **1 worker = 1 видео одновременно** (если 1 GPU на worker)
    - **Если несколько GPU**: можно обрабатывать N видео параллельно (N = количество GPU)
    - **Queue-based**: несколько worker'ов читают из одной очереди (автоматическая балансировка нагрузки)
    - **Auto-scaling**: можно настроить автоматическое добавление worker'ов при росте очереди (Kubernetes HPA или простой скрипт)
    - **Мониторинг**: отслеживаем `queue_length` и `worker_count` для принятия решений о масштабировании

- **Q64. Triton deployment**: предлагаю:
  - отдельный сервер/контейнер для Triton (не на worker'ах),
  - несколько реплик Triton для высокой нагрузки (load balancing),
  - версии моделей фиксируются в конфиге DataProcessor (какую версию какого модели использовать).
  - **A (ок/не ок, как выбираем версии моделей: из конфига или из профиля анализа)**: да
  - **Рекомендация**: **Версии моделей из конфига DataProcessor**:
    - **Конфиг YAML**: `triton_models.yaml` с mapping `component_name → model_name:version`
    - **Обновление**: при деплое DataProcessor обновляется конфиг → все новые runs используют новые версии
    - **Кэширование**: старые runs с другими версиями моделей остаются валидными (не ломаем воспроизводимость)
    - **Альтернатива (для будущего)**: можно добавить возможность указывать версию модели в профиле анализа, но это усложняет кэширование и воспроизводимость

- **Q65. MinIO/S3 доступ**: как worker'ы получают доступ:
  - через единый endpoint + credentials (env vars),
  - каждый worker имеет свои credentials (для audit),
  - или используем service account/role-based access.
  - **A**: реши сам
  - **Рекомендация**: **Единый endpoint + credentials (env vars) для MVP**:
    - Все worker'ы используют одни и те же credentials (MinIO access key + secret key)
    - Credentials в env vars (не в коде, не в git)
    - **Для будущего**: можно добавить role-based access (каждый worker со своими credentials для audit), но для MVP это избыточно
    - **Безопасность**: MinIO должен быть доступен только внутри приватной сети (не публичный endpoint)

- **Q66. Deployment strategy (MVP)**: предлагаю:
  - Docker containers для каждого сервиса (backend, worker, Triton, MinIO, Postgres),
  - docker-compose для локальной разработки,
  - для прода: либо ручной deploy на сервер, либо простой CI-CD (git push → build → deploy).
  - **A (ок/не ок, какая стратегия для MVP прода)**: реши сам, но мы двигаемся по серьезному пути в плане Масштабирования и deployment
  - **Рекомендация**: **Docker + docker-compose для MVP, Kubernetes для будущего**:
    - **MVP (простой вариант)**:
      - Docker containers для каждого сервиса
      - `docker-compose.yml` для локальной разработки
      - Для прода: ручной deploy на сервер через `docker-compose up -d` или простой CI-CD (GitHub Actions → SSH deploy)
    - **Будущее (масштабирование)**:
      - Kubernetes для оркестрации (auto-scaling, health checks, rolling updates)
      - Helm charts для управления конфигурацией
      - CI-CD pipeline (GitHub Actions → build images → push to registry → deploy to K8s)
    - **Старт**: можно начать с docker-compose, потом мигрировать на K8s когда понадобится масштабирование

#### 17) Тестирование и качество

- **Q67. Тестовые данные**: откуда берём тестовые видео для интеграционных тестов:
  - фиксированный набор небольших видео в репозитории (для CI),
  - отдельный test dataset (небольшие видео специально для тестов),
  - или используем публичные YouTube видео (стабильные ID, которые не удалят).
  - **A**: У меня есть датасет на HF
  - **Рекомендация**: **HuggingFace dataset — отлично**:
    - Использовать фиксированный набор видео из датасета для CI тестов
    - Видео должны быть небольшими (< 1 минуты) для быстрых тестов
    - Хранить список video_id в репозитории (для воспроизводимости)
    - **Дополнительно**: можно добавить несколько публичных YouTube видео как fallback (если HF dataset недоступен)

- **Q68. E2E тесты (MVP)**: нужно ли делать:
  - да, минимум 1 E2E тест: “скачать видео → Segmenter → Visual → проверить manifest/NPZ артефакты”,
  - нет, достаточно unit + integration тестов компонентов,
  - или только ручное тестирование на MVP.
  - **A**: обязательно
  - **Рекомендация**: **E2E тест — критично для качества**:
    - **Минимальный E2E тест**:
      1. Скачать видео (или использовать из HF dataset)
      2. Запустить Segmenter → Audio → Text → Visual
      3. Проверить, что все NPZ артефакты созданы
      4. Проверить, что `manifest.json` валиден и содержит все компоненты
      5. Проверить, что `frame_indices` согласованы между компонентами
    - **Реализация**: использовать `pytest` с фикстурами для запуска полного пайплайна
    - **CI**: запускать E2E тест в CI на каждом PR (может быть медленным, но критично)

- **Q69. Тестирование на больших видео**: как тестируем производительность:
  - включаем в CI тесты на видео разной длины (короткие/средние/20 мин),
  - отдельные performance тесты (не в каждом PR, но периодически),
  - или только manual тестирование на проде.
  - **A**: включаем в CI тесты на видео разной длины (короткие/средние/20 мин)
  - **Рекомендация**: **Performance тесты в CI**:
    - **Структура тестов**:
      - Короткие видео (< 30 сек): быстрые тесты, запускаются на каждом PR
      - Средние видео (2-5 мин): запускаются на main branch или nightly
      - Длинные видео (20 мин): запускаются периодически (раз в неделю) или вручную
    - **Метрики**: измеряем время обработки per component и сравниваем с baseline
    - **Алерты**: если время обработки выросло > 20% → предупреждение

#### 18) Безопасность и auth

- **Q70. Аутентификация backend ↔ DataProcessor**: нужна ли:
  - API key в заголовках (простой вариант для MVP),
  - mTLS (взаимная TLS-аутентификация, более безопасно),
  - или в MVP можно без auth (worker доступен только внутри приватной сети).
  - **A**: mTLS
  - **Рекомендация**: **mTLS — правильный выбор для безопасности**:
    - **Реализация**: использовать библиотеку `certifi` и настройку TLS в HTTP клиенте/сервере
    - **Сертификаты**: генерируем self-signed certificates для dev, для прода используем Let's Encrypt или внутренний CA
    - **Конфигурация**: certificates в secrets (env vars или Kubernetes secrets)
    - **Альтернатива для MVP**: можно начать с API key в заголовках (проще), потом мигрировать на mTLS
    - **Важно**: если worker'ы в приватной сети → mTLS опционален, но рекомендуется для будущего

- **Q71. Rate limiting (MVP)**: нужен ли на уровне:
  - backend API (лимит запросов от пользователя, например, 10 анализов/час),
  - DataProcessor worker (лимит задач от backend, например, не более 100 задач/час),
  - или пока без rate limiting (контролируем через очередь и кредиты).
  - **A**: Лимит будет зависеть от подписки пользователя, но будет и жесткое ограничение с которым определимся позже
  - **Рекомендация**: **Многоуровневый rate limiting**:
    - **Backend API**: лимит per user зависит от подписки (free: 5 анализов/час, premium: 50 анализов/час)
    - **Жёсткое ограничение**: максимум 100 анализов/час на пользователя (даже для premium) — защита от злоупотреблений
    - **DataProcessor worker**: лимит на уровне очереди (не более N задач в секунду от одного backend)
    - **Реализация**: использовать `slowapi` (FastAPI rate limiting) или Redis-based rate limiter
    - **Мониторинг**: логируем все rate limit hits для анализа

- **Q72. Secrets management**: как храним секреты (API keys для LLM, credentials для MinIO/S3, YouTube API keys):
  - env vars в docker-compose/.env (для dev),
  - secrets в deployment (Kubernetes secrets, или просто env vars в prod, но не в git),
  - или используем внешний secrets manager (HashiCorp Vault, AWS Secrets Manager — для будущего).
  - **A (что используем на MVP)**: Реши сам, но мне нравиться внешний secrets
  - **Рекомендация**: **Поэтапный подход**:
    - **MVP (простой вариант)**: env vars в `.env` файле (не в git), передаются через docker-compose или deployment скрипт
    - **Следующий этап**: Kubernetes secrets (если используем K8s)
    - **Будущее**: внешний secrets manager (HashiCorp Vault, AWS Secrets Manager)
    - **Важно**: никогда не коммитить secrets в git, использовать `.gitignore` для `.env` файлов
    - **Ротация**: планировать механизм ротации secrets (особенно для LLM API keys)

#### 19) Batch processing и массовая обработка

- **Q73. Batch режим в проде**: будет ли:
  - нет, только по одному видео (пользователь запускает анализ через UI),
  - да, но только для админов (mass processing через админку),
  - или планируется публичный batch API (загрузка списка URL, обработка всех).
  - **A**: батчинг будет. Как минимум я вижу такую картину: сделать очередь прям на backend то есть 1 пользователь запрашивает 1 анализ и у него уже идет прогресс, но в этот момент на самом деле ничего не идет а backend еще какое то время ждет (5-10 сек) что бы возможно собрать еще запросов и потом разом все отправляет. ну и соответственно несколько режимов батчинга в самом DataProcessor на всех уровнях. Я Вроде где то говорил про динамический батчинг зависящий от памяти и ресурсозатратности каждого отдельного модуля (используя заранее подготовленныей чек-лист).
  - **Рекомендация**: **Многоуровневый батчинг — отличная идея**:
    - **Backend-level batching**:
      - Backend собирает запросы в буфер (5-10 секунд)
      - Отправляет batch в очередь DataProcessor
      - Пользователь видит "в очереди" сразу (не ждёт реальной обработки)
    - **DataProcessor-level batching**:
      - **Динамический батчинг per component**: каждый компонент решает, сколько задач обрабатывать параллельно
      - **Чек-лист ресурсов**: таблица `component_resource_requirements`:
        - `memory_per_task` (MB)
        - `gpu_memory_per_task` (MB)
        - `cpu_cores_per_task`
      - **Алгоритм**: worker читает задачи из очереди и группирует их в batch, учитывая доступные ресурсы
      - **Пример**: если доступно 8GB GPU memory, а `face_emotion` требует 2GB per task → batch size = 4
    - **Реализация**: использовать библиотеку для динамического батчинга или реализовать custom logic в worker'е

- **Q74. Приоритизация задач**: если в очереди много задач:
  - FIFO (first in, first out),
  - приоритеты (например, “premium users” обрабатываются быстрее),
  - или пока без приоритетов (MVP = FIFO).
  - **A**: FIFO
  - **Рекомендация**: **FIFO для MVP — правильно**:
    - Простота реализации (стандартное поведение очереди)
    - Справедливость (первый пришёл — первый обслужен)
    - **Будущее**: можно добавить приоритеты позже (premium users обрабатываются быстрее), но для MVP FIFO достаточно
    - **Реализация**: большинство queue систем (Redis/RabbitMQ) поддерживают FIFO по умолчанию

#### 20) Версионирование моделей и конфигурация Triton

- **Q75. Выбор версии модели (Triton)**: предлагаю:
  - версия модели фиксируется в `dataprocessor_version` (все run'ы одной версии DataProcessor используют одинаковые версии моделей),
  - или версия модели может быть частью `config_hash` (разные профили могут использовать разные версии моделей, но это усложняет кэширование).
  - **A**: реши сам
  - **Рекомендация**: **Версия модели фиксируется в `dataprocessor_version`**:
    - Все run'ы одной версии DataProcessor используют одинаковые версии моделей
    - Это упрощает кэширование и воспроизводимость
    - **Альтернатива (не рекомендуется)**: версия модели в `config_hash` усложняет кэширование (разные профили = разные версии моделей = разные кэши)
    - **Обновление моделей**: при обновлении DataProcessor обновляются версии моделей → все новые runs используют новые версии
    - **Старые runs**: остаются валидными с старыми версиями моделей (не ломаем воспроизводимость)

- **Q76. Конфигурация Triton models**: где храним mapping “component → model name + version”:
  - в конфиге DataProcessor (YAML, обновляется при деплое),
  - в БД (админка может менять версии моделей без деплоя),
  - или фиксируем в коде (проще, но требует деплоя для смены версии).
  - **A**: реши сам
  - **Рекомендация**: **Конфиг DataProcessor (YAML) для MVP, БД для будущего**:
    - **MVP**: `triton_models.yaml` в репозитории DataProcessor:
      ```yaml
      models:
        face_emotion:
          name: "emotion_net"
          version: "v1.2"
        object_detection:
          name: "yolox"
          version: "v2.0"
      ```
    - **Обновление**: при деплое DataProcessor обновляется конфиг
    - **Будущее**: можно перенести в БД для возможности изменения версий без деплоя (через админку)
    - **Компромисс**: конфиг в коде проще и надёжнее для MVP, БД даёт гибкость но требует дополнительной инфраструктуры

---

### Round 3 — зафиксировано (полуфинальные решения)

#### Backend ↔ DataProcessor коммуникация
- **Протокол**: Queue-based (Redis/RabbitMQ) для асинхронной обработки, опциональный синхронный HTTP endpoint для тестов
- **Payload**: обязательные поля: `run_id`, `video_id`, `platform_id`, `config_hash`, `sampling_policy_version`, `dataprocessor_version`, `video_source`, `user_id`
- **Статус прогресса**: гибридный подход — polling (основной) + опциональные webhooks

#### Billing и стоимость
- **Единица биллинга**: комбинированная формула с ресурсной моделью (base_cost + compute_time × rate + gpu_time × rate + markup)
- **Списание**: резервирование при создании run, списание после завершения по факту успешных компонентов, возврат разницы
- **Ценообразование**: прайс-лист компонентов в БД с параметрами (base_cost, cpu_cost_per_sec, gpu_cost_per_sec, scaling factors)
- **Оценка стоимости**: backend рассчитывает локально из прайс-листа (1 рубль = 1 единица для старта)

#### Error handling и retry
- **Retry политика**: ретраим только transient errors (network/timeout/OOM) с exponential backoff, не ретраим логические ошибки
- **Network errors**: YouTube download (3 попытки), Triton (2 попытки для transient), LLM gateway (2 попытки, rate limit → ошибка пользователю)
- **OOM handling**: автоматическое уменьшение batch_size/chunk_size с ретраем (максимум 2 попытки), если не помогло → error

#### Edge cases
- **Видео > 20 минут**: отказ с ошибкой `video_too_long` (валидация на входе в backend)
- **Повреждённые файлы**: автоматическое исправление через ffmpeg (`-err_detect ignore_err`, перекодирование с `-crf 18`), timeout 5 минут
- **Видео без звука**: AudioProcessor компоненты получают `empty_reason="audio_missing_or_extract_failed"`, run продолжается (если audio не required)
- **Видео < 5 секунд**: отказ с ошибкой `video_too_short` (валидация на входе)

#### Video download и preprocessing
- **YouTube download**: yt-dlp с форматом до 1080p, динамический timeout, 3 попытки с backoff
- **Preprocessing**: в Segmenter (конвертация формата, downscale до 1080p с `lanczos`, без потери качества)
- **Временное хранилище**: локальный диск worker'а (`/tmp/trendflow/{run_id}/video.mp4`), удаление после Segmenter

#### Мониторинг
- **Health checks**: `/health` (readiness), `/health/live` (liveness) для всех сервисов
- **Метрики**: Prometheus + Grafana (runs_total, success_rate, component_duration, gpu_utilization, queue_length, errors_total)
- **Alerting**: сервис недоступен, очередь переполнена, success rate < 80%, GPU OOM часто, время обработки выросло

#### Масштабирование и deployment
- **Workers**: горизонтальное масштабирование через queue, 1 worker = 1 видео (или N при нескольких GPU)
- **Triton**: отдельный сервер/контейнер, версии моделей из конфига DataProcessor
- **MinIO доступ**: единый endpoint + credentials (env vars) для MVP
- **Deployment**: Docker + docker-compose для MVP, Kubernetes для будущего масштабирования

#### Тестирование
- **Тестовые данные**: HuggingFace dataset (фиксированный набор для CI)
- **E2E тесты**: обязательно (Segmenter → Audio → Text → Visual → проверка артефактов)
- **Performance тесты**: в CI на видео разной длины (короткие на каждом PR, средние/длинные периодически)

#### Безопасность
- **Аутентификация**: mTLS между backend и DataProcessor (self-signed для dev, Let's Encrypt для prod)
- **Rate limiting**: многоуровневый (per user по подписке, жёсткий максимум 100/час, на уровне очереди)
- **Secrets management**: поэтапный подход (env vars для MVP → Kubernetes secrets → внешний secrets manager)

#### Batch processing
- **Backend-level batching**: сбор запросов в буфер (5-10 сек) перед отправкой в очередь
- **DataProcessor-level batching**: динамический батчинг per component на основе ресурсных требований (чек-лист в БД)
- **Приоритизация**: FIFO для MVP

#### Версионирование моделей
- **Версии моделей**: фиксируются в `dataprocessor_version` (все run'ы одной версии используют одинаковые версии)
- **Конфигурация Triton**: `triton_models.yaml` в репозитории DataProcessor для MVP, БД для будущего

---
